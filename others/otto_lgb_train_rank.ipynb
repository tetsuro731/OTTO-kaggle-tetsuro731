{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6598,"status":"ok","timestamp":1673488133965,"user":{"displayName":"テッツォ","userId":"07789339878611604425"},"user_tz":-540},"id":"8QrdrLFrx86e","outputId":"4548bcc7-3c2b-4df1-8fc6-3265b240b655"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","test_50.parquet\t\t       train_20.parquet\n","test_50_tmp.parquet\t       train_20_tmp.parquet\n","test_aid_features.parquet      train_50.parquet\n","test.parquet\t\t       train_50_tmp.parquet\n","test_preds.csv\t\t       train.parquet\n","test_session_features.parquet  valid_aid_features.parquet\n","train_20_old2.parquet\t       valid_session_features.parquet\n","train_20_old.parquet\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: optuna in /usr/local/lib/python3.8/dist-packages (3.0.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (21.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.8/dist-packages (from optuna) (6.7.0)\n","Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.7.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna) (4.64.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.4.46)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (1.9.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna) (1.21.6)\n","Requirement already satisfied: cliff in /usr/local/lib/python3.8/dist-packages (from optuna) (4.1.0)\n","Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.8/dist-packages (from optuna) (4.13.0)\n","Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from optuna) (0.9.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (5.10.2)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna) (1.2.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata<5.0.0->optuna) (3.11.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n","Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna) (3.6.0)\n","Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna) (2.4.2)\n","Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna) (4.1.1)\n","Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from cliff->optuna) (0.5.1)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.2.0)\n","Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from stevedore>=2.0.1->cliff->optuna) (5.11.1)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n"]}],"source":["# True: Google Colab Notebook\n","# False: My local PC\n","colab = True\n","if colab: \n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    !ls /content/drive/MyDrive/output/otto/\n","    base_path = '/content/drive/MyDrive'\n","    !pip3 install optuna\n","else:\n","    base_path = '../data'"]},{"cell_type":"markdown","metadata":{"id":"rApCp4mVyLAk"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":585,"status":"ok","timestamp":1673488134547,"user":{"displayName":"テッツォ","userId":"07789339878611604425"},"user_tz":-540},"id":"S8Rxu2iww5-9"},"outputs":[],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import gc\n","import warnings\n","warnings.filterwarnings('ignore')\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","import itertools\n","from imblearn.under_sampling import RandomUnderSampler"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":14516,"status":"ok","timestamp":1673488149062,"user":{"displayName":"テッツォ","userId":"07789339878611604425"},"user_tz":-540},"id":"oujqBvdabvAs"},"outputs":[],"source":["#train = pd.read_parquet('/content/drive/MyDrive/output/otto/train.parquet')\n","#train = pd.read_parquet('/content/drive/MyDrive/output/otto/train_20.parquet')\n","#train = pd.read_parquet('/content/drive/MyDrive/output/otto/train_50.parquet')\n","train = pd.read_parquet(f'{base_path}/output/otto/train_50_tmp.parquet')\n","\n","#train = pd.read_parquet('/content/drive/MyDrive/output/otto/train_20_old.parquet')\n","\n","#train20 = pd.read_parquet('/content/drive/MyDrive/output/otto/train_20.parquet')"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1673488149063,"user":{"displayName":"テッツォ","userId":"07789339878611604425"},"user_tz":-540},"id":"nE1xweGKyW0a"},"outputs":[],"source":["DEBUG_MODE = False\n","#DEBUG_MODE = True\n","\n","OPTUNA_FLAG = False\n","#OPTUNA_FLAG = True\n","\n","if DEBUG_MODE:\n","    train = train.head(100000)\n","IGNORE_COL = ['session','aid']\n","\n","#TYPE_MODE = 'clicks'\n","#TYPE_MODE = 'carts'\n","TYPE_MODE = 'orders'\n","TARGET_COL = ['y_clicks', 'y_carts', 'y_orders']\n","IGNORE_COL += TARGET_COL\n","\n","if TYPE_MODE == 'clicks':\n","    target = 'y_clicks'\n","    # under sampling 1.3 -> 2.5%\n","    pos_neg_ratio = 1/39\n","elif TYPE_MODE == 'carts':\n","    target = 'y_carts'\n","    # under sampling 1.6 -> 2.5%\n","    pos_neg_ratio = 1/39\n","elif TYPE_MODE == 'orders':\n","    target = 'y_orders'\n","    # under sampling 2.1 -> 2.5%\n","    pos_neg_ratio = 1/39"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1673488149063,"user":{"displayName":"テッツォ","userId":"07789339878611604425"},"user_tz":-540},"id":"ZHnc3hihwSHY"},"outputs":[],"source":["def reduce_memory(df):\n","    df['session'] = df['session'].astype('int32')\n","    df['aid'] = df['aid'].astype('int32')\n","    df['score_click'] = df['score_click'].astype('float32')\n","    df['score_cart'] = df['score_cart'].astype('float32')\n","    df['score_buy'] = df['score_buy'].astype('float32')\n","    df['score_click_only'] = df['score_click_only'].astype('float32')\n","    df['score_cart_only'] = df['score_cart_only'].astype('float32')\n","    df['score_buy_only'] = df['score_buy_only'].astype('float32')\n","    df['session_action_count'] = df['session_action_count'].astype('int16')\n","    df['session_click_count'] = df['session_click_count'].astype('int16')\n","    df['session_cart_count'] = df['session_cart_count'].astype('int16')\n","    df['session_order_count'] = df['session_order_count'].astype('int16')\n","    df['session_type_mean'] = df['session_type_mean'].astype('float32')\n","    \n","    click_topn_list = [10, 20]\n","    for i in click_topn_list:\n","        df[f'n_clicks_{i}'] = df[f'n_clicks_{i}'].astype('int8')\n","\n","    df['n_carts'] = df['n_carts'].astype('int8')\n","    df['n_buys'] = df['n_buys'].astype('int8')\n","    df['clicks_count'] = df['clicks_count'].astype('int32')\n","    df['carts_count'] = df['carts_count'].astype('int16')\n","    df['orders_count'] = df['orders_count'].astype('int16')\n","    return df\n","\n","# topn件だけを使う\n","def use_top_n(n, df):\n","    df = df.query(f'score_click >= -1 or score_cart >= -1 or score_buy >= -1 or (-1 < n_clicks_20 and n_clicks_20<{n}) or (-1 < n_carts and n_carts<{n}) or (-1 < n_buys and n_buys<{n})')\n","    return df\n","\n","# 負例しかないものは学習に使えないので削る（学習のみ）\n","def remove_negative_session(df):\n","    true_df = df.groupby('session')[target].agg('sum') > 0\n","    session = pd.DataFrame(true_df[true_df]).reset_index()['session']\n","    df = df.merge(session, how = 'inner', on = 'session')\n","    return df\n","\n","# 負例が多すぎる場合にunder samplingする\n","# ratio = pos/neg\n","def negative_sampling(df_x, df_y, ratio):\n","    print('before mean:', df_y.mean())\n","\n","    Nrow = df_x.shape[0]\n","    Ndiv = 5\n","    n = int(Nrow // Ndiv) + 1\n","\n","    df_x_list = [df_x.iloc[i*n : (i+1)*n, :] for i in range(Ndiv)]\n","    df_y_list = [df_y.iloc[i*n : (i+1)*n] for i in range(Ndiv)]\n","    del df_x, df_y\n","    gc.collect()\n","\n","    for i in range(Ndiv):\n","        print('under sampling.......',i + 1 , '/', Ndiv)\n","        tmpx, tmpy = RandomUnderSampler(sampling_strategy=ratio).fit_resample(df_x_list[i], df_y_list[i])\n","        df_x_list[i] = tmpx\n","        df_y_list[i] = tmpy\n","        del tmpx, tmpy\n","        gc.collect()\n","    print('under sampling end')\n","    after_x = pd.concat(df_x_list)\n","    del df_x_list\n","    gc.collect()\n","    print('post proccess1')\n","    after_y = pd.concat(df_y_list)\n","    del df_y_list\n","    gc.collect()\n","    # sessionの順番がばらばらになるので再びsort\n","    tmp = pd.concat([after_x, after_y], axis=1).sort_values('session')\n","    after_y = tmp[target]\n","    after_x = tmp.drop(target , axis=1)\n","\n","    print('after mean:', after_y.mean())\n","    return after_x, after_y"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1673488149064,"user":{"displayName":"テッツォ","userId":"07789339878611604425"},"user_tz":-540},"id":"KvbDeqvHbMn8"},"outputs":[],"source":["def join_session_features(df):\n","    session_df = pd.read_parquet('/content/drive/MyDrive/output/otto/valid_session_features.parquet')\n","    session_df['session'] = session_df['session'].astype('int32')\n","    session_df[f'session_action_count'] = session_df[f'session_action_count'].astype('int16')\n","    session_df[f'session_click_count'] = session_df[f'session_click_count'].astype('int16')\n","    session_df[f'session_cart_count'] = session_df[f'session_cart_count'].astype('int16')\n","    session_df[f'session_order_count'] = session_df[f'session_order_count'].astype('int16')\n","    session_df[f'session_type_mean'] = session_df[f'session_type_mean'].astype('float32')\n","    session_df[f'session_click_rate'] = session_df[f'session_click_rate'].astype('float32')\n","    session_df[f'session_cart_rate'] = session_df[f'session_cart_rate'].astype('float32')\n","    session_df[f'session_order_rate'] = session_df[f'session_order_rate'].astype('float32')\n","\n","    remove_col = ['session_action_count', 'session_click_count', 'session_cart_count', 'session_order_count', 'session_type_mean']\n","    df = df.drop(remove_col , axis=1)\n","    df = df.merge(session_df, 'left', 'session')\n","    del session_df\n","    gc.collect()\n","    \n","    return df"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1673488149064,"user":{"displayName":"テッツォ","userId":"07789339878611604425"},"user_tz":-540},"id":"TT-tm_hPbPpA"},"outputs":[],"source":["def join_aid_features(df):\n","    aid_df = pd.read_parquet(f'{base_path}/output/otto/valid_aid_features.parquet')\n","    #week_list = ['4weeks', '3weeks', '2weeks', '1week']\n","    week_list = ['4weeks', '2weeks', '1week']\n","    aid_df['aid'] = aid_df['aid'].astype('int32')\n","    for i in week_list:\n","        aid_df[f'clicks_count_{i}'] = aid_df[f'clicks_count_{i}'].astype('int32')\n","        aid_df[f'carts_count_{i}'] = aid_df[f'carts_count_{i}'].astype('int16')\n","        aid_df[f'orders_count_{i}'] = aid_df[f'orders_count_{i}'].astype('int16')\n","        aid_df[f'clicks_rank_{i}'] = aid_df[f'clicks_rank_{i}'].astype('int32')\n","        aid_df[f'carts_rank_{i}'] = aid_df[f'carts_rank_{i}'].astype('int32')\n","        aid_df[f'orders_rank_{i}'] = aid_df[f'orders_rank_{i}'].astype('int32')\n","        for j in ['clicks', 'carts', 'orders']:\n","            #for k in [2,3,4]:\n","            for k in [2,4]:\n","                aid_df[f'aid_{j}_count_rate_1_{k}'] = aid_df[f'aid_{j}_count_rate_1_{k}'].astype('float32')\n","\n","    remove_col = ['clicks_rank', 'carts_rank', 'orders_rank', 'clicks_count', 'carts_count', 'orders_count']\n","    #remove_col = ['clicks_rank_1week', 'carts_rank_1week', 'orders_rank_1week', 'clicks_count_1week', 'carts_count_1week', 'orders_count_1week']\n","    #df.drop(remove_col , axis=1)\n","    df = df.merge(aid_df, 'left', 'aid')\n","    del aid_df\n","    gc.collect()\n","    \n","    return df"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"fr7uXIlVxvEJ","executionInfo":{"status":"ok","timestamp":1673488170458,"user_tz":-540,"elapsed":21399,"user":{"displayName":"テッツォ","userId":"07789339878611604425"}}},"outputs":[],"source":["train = reduce_memory(train)\n","train = use_top_n(50, train)\n","train = remove_negative_session(train)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yyec9GHZypQ5","executionInfo":{"status":"ok","timestamp":1673488170459,"user_tz":-540,"elapsed":28,"user":{"displayName":"テッツォ","userId":"07789339878611604425"}},"outputId":"82364e00-7915-445c-84f4-8d8a0162d2f0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["216155"]},"metadata":{},"execution_count":9}],"source":["train[target].sum()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RGToJvwN2dxO","executionInfo":{"status":"ok","timestamp":1673488170459,"user_tz":-540,"elapsed":23,"user":{"displayName":"テッツォ","userId":"07789339878611604425"}},"outputId":"3d003de0-00a7-4f2b-ebce-ec63e838ab12"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.021850287898556357"]},"metadata":{},"execution_count":10}],"source":["train[target].mean()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"bmasKtdlgXRF","executionInfo":{"status":"ok","timestamp":1673488191256,"user_tz":-540,"elapsed":20817,"user":{"displayName":"テッツォ","userId":"07789339878611604425"}}},"outputs":[],"source":["train = join_session_features(train)\n","train = join_aid_features(train)"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"QkjpGWm5LUwq","executionInfo":{"status":"ok","timestamp":1673488191256,"user_tz":-540,"elapsed":21,"user":{"displayName":"テッツォ","userId":"07789339878611604425"}}},"outputs":[],"source":["# WIP\n","TRAIN_SECOND = False\n","if TRAIN_SECOND:\n","    # target以外の予測値の読み込み\n","    train = pd.read_csv(f'{base_path}/otto/oof_lgbm_{TYPE_MODE}.csv')"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":488},"id":"XWIbhd2JjWM7","executionInfo":{"status":"ok","timestamp":1673488191257,"user_tz":-540,"elapsed":21,"user":{"displayName":"テッツォ","userId":"07789339878611604425"}},"outputId":"50d8f36b-e208-4015-d9e9-c7ea9c460c37"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["          session      aid  score_click  score_cart  score_buy  score_click_only  score_cart_only  score_buy_only  n_clicks_10  n_clicks_20  n_carts  n_buys  clicks_rank  carts_rank  orders_rank  clicks_count  carts_count  orders_count  y_clicks  y_carts  y_orders  session_action_count  session_click_count  session_cart_count  session_order_count  session_type_mean  session_click_rate  session_cart_rate  session_order_rate  clicks_count_4weeks  carts_count_4weeks  orders_count_4weeks  clicks_rank_4weeks  carts_rank_4weeks  orders_rank_4weeks  clicks_count_2weeks  carts_count_2weeks  orders_count_2weeks  clicks_rank_2weeks  carts_rank_2weeks  orders_rank_2weeks  clicks_count_1week  carts_count_1week  orders_count_1week  clicks_rank_1week  carts_rank_1week  orders_rank_1week  aid_clicks_count_rate_1_2  aid_clicks_count_rate_1_4  aid_carts_count_rate_1_2  aid_carts_count_rate_1_4  aid_orders_count_rate_1_2  aid_orders_count_rate_1_4\n","0        11098528    11830     0.071773    0.071773        0.0          0.071773              0.0             0.0           -1           -1       -1      -1          190         111          147          1087          127            16     False    False      True                     1                    1                   0                    0               0.00            0.999999               0.00                0.00                28997                3682                 1097                  82                 43                  54                 8178                 920                  285                 164                103                 102                1087                127                  16                189               111                150                   0.132918                   0.037487                  0.138043                  0.034492                   0.056140                   0.014585\n","1        11098528   588923          NaN         NaN        NaN               NaN              NaN             NaN            0            0        0       1          625         366          365           553           69            10     False    False     False                     1                    1                   0                    0               0.00            0.999999               0.00                0.00                22162                1770                  656                 155                207                 190                 6326                 499                  161                 288                343                 343                 553                 69                  10                625               360                350                   0.087417                   0.024953                  0.138277                  0.038983                   0.062112                   0.015244\n","2        11098528  1732105          NaN         NaN        NaN               NaN              NaN             NaN            1            1        1       0         2316         335          650           251           73             7     False    False     False                     1                    1                   0                    0               0.00            0.999999               0.00                0.00                 8049                1877                  526                1107                186                 282                 2239                 459                  140                1804                396                 459                 251                 73                   7               2314               339                784                   0.112104                   0.031184                  0.159041                  0.038892                   0.050000                   0.013308\n","3        11098528   571762          NaN         NaN        NaN               NaN              NaN             NaN            2            2        2       4          574         811          804           586           44             7     False    False     False                     1                    1                   0                    0               0.00            0.999999               0.00                0.00                17021                1257                  544                 277                401                 266                 5312                 398                  160                 416                520                 345                 586                 44                   7                574               827                761                   0.110316                   0.034428                  0.110553                  0.035004                   0.043750                   0.012868\n","4        11098528   884502          NaN         NaN        NaN               NaN              NaN             NaN            3            3        3       2          234         166          118           981          105            17     False    False     False                     1                    1                   0                    0               0.00            0.999999               0.00                0.00                28184                2408                  930                  91                118                  91                 8610                 688                  250                 152                190                 144                 981                105                  17                234               167                121                   0.113937                   0.034807                  0.152616                  0.043605                   0.068000                   0.018280\n","...           ...      ...          ...         ...        ...               ...              ...             ...          ...          ...      ...     ...          ...         ...          ...           ...          ...           ...       ...      ...       ...                   ...                  ...                 ...                  ...                ...                 ...                ...                 ...                  ...                 ...                  ...                 ...                ...                 ...                  ...                 ...                  ...                 ...                ...                 ...                 ...                ...                 ...                ...               ...                ...                        ...                        ...                       ...                       ...                        ...                        ...\n","9892542  12899525  1556052          NaN         NaN        NaN               NaN              NaN             NaN           -1           -1       -1      35        89698      169933           -1            13            1             0     False    False     False                     8                    4                   2                    2               0.75            0.500000               0.25                0.25                  374                  41                   16               69602              56648               42786                  142                  11                    4               67165              78051               71202                  13                  1                   0              87131            169937                 -1                   0.091549                   0.034759                  0.090909                  0.024390                   0.000000                   0.000000\n","9892543  12899525   500570          NaN         NaN        NaN               NaN              NaN             NaN           -1           -1       -1      42         2180         631          725           261           51             7     False    False     False                     8                    4                   2                    2               0.75            0.500000               0.25                0.25                 7404                1235                  342                1273                417                 621                 2879                 522                  135                1191                318                 489                 261                 51                   7               2191               639                701                   0.090656                   0.035251                  0.097701                  0.041296                   0.051852                   0.020468\n","9892544  12899525  1373578          NaN         NaN        NaN               NaN              NaN             NaN           -1           -1       -1      43       332706      124681           -1             3            1             0     False    False     False                     8                    4                   2                    2               0.75            0.500000               0.25                0.25                   52                   6                    1              373850             314923              406989                   27                   3                    1              288523             235878              196449                   3                  1                   0             299760            123148                 -1                   0.111111                   0.057692                  0.333333                  0.166667                   0.000000                   0.000000\n","9892545  12899525   787412          NaN         NaN        NaN               NaN              NaN             NaN           -1           -1       -1      48        85291       27285        31628            14            4             1     False    False     False                     8                    4                   2                    2               0.75            0.500000               0.25                0.25                  510                  75                   31               50523              28568               21611                  120                  14                    7               79787              64324               37254                  14                  4                   1              81767             29421              31627                   0.116667                   0.027451                  0.285714                  0.053333                   0.142857                   0.032258\n","9892546  12899525  1357950          NaN         NaN        NaN               NaN              NaN             NaN           -1           -1       -1      49       150784      169756           -1             8            1             0     False    False     False                     8                    4                   2                    2               0.75            0.500000               0.25                0.25                  274                  18                    3               94711             125051              191076                   87                   8                    2              108121             111462              121158                   8                  1                   0             148855            169757                 -1                   0.091954                   0.029197                  0.125000                  0.055556                   0.000000                   0.000000\n","\n","[9892547 rows x 53 columns]"],"text/html":["\n","  <div id=\"df-69597553-c541-4511-97f1-63283e808b2d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session</th>\n","      <th>aid</th>\n","      <th>score_click</th>\n","      <th>score_cart</th>\n","      <th>score_buy</th>\n","      <th>score_click_only</th>\n","      <th>score_cart_only</th>\n","      <th>score_buy_only</th>\n","      <th>n_clicks_10</th>\n","      <th>n_clicks_20</th>\n","      <th>n_carts</th>\n","      <th>n_buys</th>\n","      <th>clicks_rank</th>\n","      <th>carts_rank</th>\n","      <th>orders_rank</th>\n","      <th>clicks_count</th>\n","      <th>carts_count</th>\n","      <th>orders_count</th>\n","      <th>y_clicks</th>\n","      <th>y_carts</th>\n","      <th>y_orders</th>\n","      <th>session_action_count</th>\n","      <th>session_click_count</th>\n","      <th>session_cart_count</th>\n","      <th>session_order_count</th>\n","      <th>session_type_mean</th>\n","      <th>session_click_rate</th>\n","      <th>session_cart_rate</th>\n","      <th>session_order_rate</th>\n","      <th>clicks_count_4weeks</th>\n","      <th>carts_count_4weeks</th>\n","      <th>orders_count_4weeks</th>\n","      <th>clicks_rank_4weeks</th>\n","      <th>carts_rank_4weeks</th>\n","      <th>orders_rank_4weeks</th>\n","      <th>clicks_count_2weeks</th>\n","      <th>carts_count_2weeks</th>\n","      <th>orders_count_2weeks</th>\n","      <th>clicks_rank_2weeks</th>\n","      <th>carts_rank_2weeks</th>\n","      <th>orders_rank_2weeks</th>\n","      <th>clicks_count_1week</th>\n","      <th>carts_count_1week</th>\n","      <th>orders_count_1week</th>\n","      <th>clicks_rank_1week</th>\n","      <th>carts_rank_1week</th>\n","      <th>orders_rank_1week</th>\n","      <th>aid_clicks_count_rate_1_2</th>\n","      <th>aid_clicks_count_rate_1_4</th>\n","      <th>aid_carts_count_rate_1_2</th>\n","      <th>aid_carts_count_rate_1_4</th>\n","      <th>aid_orders_count_rate_1_2</th>\n","      <th>aid_orders_count_rate_1_4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11098528</td>\n","      <td>11830</td>\n","      <td>0.071773</td>\n","      <td>0.071773</td>\n","      <td>0.0</td>\n","      <td>0.071773</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>190</td>\n","      <td>111</td>\n","      <td>147</td>\n","      <td>1087</td>\n","      <td>127</td>\n","      <td>16</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.00</td>\n","      <td>0.999999</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>28997</td>\n","      <td>3682</td>\n","      <td>1097</td>\n","      <td>82</td>\n","      <td>43</td>\n","      <td>54</td>\n","      <td>8178</td>\n","      <td>920</td>\n","      <td>285</td>\n","      <td>164</td>\n","      <td>103</td>\n","      <td>102</td>\n","      <td>1087</td>\n","      <td>127</td>\n","      <td>16</td>\n","      <td>189</td>\n","      <td>111</td>\n","      <td>150</td>\n","      <td>0.132918</td>\n","      <td>0.037487</td>\n","      <td>0.138043</td>\n","      <td>0.034492</td>\n","      <td>0.056140</td>\n","      <td>0.014585</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11098528</td>\n","      <td>588923</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>625</td>\n","      <td>366</td>\n","      <td>365</td>\n","      <td>553</td>\n","      <td>69</td>\n","      <td>10</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.00</td>\n","      <td>0.999999</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>22162</td>\n","      <td>1770</td>\n","      <td>656</td>\n","      <td>155</td>\n","      <td>207</td>\n","      <td>190</td>\n","      <td>6326</td>\n","      <td>499</td>\n","      <td>161</td>\n","      <td>288</td>\n","      <td>343</td>\n","      <td>343</td>\n","      <td>553</td>\n","      <td>69</td>\n","      <td>10</td>\n","      <td>625</td>\n","      <td>360</td>\n","      <td>350</td>\n","      <td>0.087417</td>\n","      <td>0.024953</td>\n","      <td>0.138277</td>\n","      <td>0.038983</td>\n","      <td>0.062112</td>\n","      <td>0.015244</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11098528</td>\n","      <td>1732105</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2316</td>\n","      <td>335</td>\n","      <td>650</td>\n","      <td>251</td>\n","      <td>73</td>\n","      <td>7</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.00</td>\n","      <td>0.999999</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>8049</td>\n","      <td>1877</td>\n","      <td>526</td>\n","      <td>1107</td>\n","      <td>186</td>\n","      <td>282</td>\n","      <td>2239</td>\n","      <td>459</td>\n","      <td>140</td>\n","      <td>1804</td>\n","      <td>396</td>\n","      <td>459</td>\n","      <td>251</td>\n","      <td>73</td>\n","      <td>7</td>\n","      <td>2314</td>\n","      <td>339</td>\n","      <td>784</td>\n","      <td>0.112104</td>\n","      <td>0.031184</td>\n","      <td>0.159041</td>\n","      <td>0.038892</td>\n","      <td>0.050000</td>\n","      <td>0.013308</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11098528</td>\n","      <td>571762</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>574</td>\n","      <td>811</td>\n","      <td>804</td>\n","      <td>586</td>\n","      <td>44</td>\n","      <td>7</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.00</td>\n","      <td>0.999999</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>17021</td>\n","      <td>1257</td>\n","      <td>544</td>\n","      <td>277</td>\n","      <td>401</td>\n","      <td>266</td>\n","      <td>5312</td>\n","      <td>398</td>\n","      <td>160</td>\n","      <td>416</td>\n","      <td>520</td>\n","      <td>345</td>\n","      <td>586</td>\n","      <td>44</td>\n","      <td>7</td>\n","      <td>574</td>\n","      <td>827</td>\n","      <td>761</td>\n","      <td>0.110316</td>\n","      <td>0.034428</td>\n","      <td>0.110553</td>\n","      <td>0.035004</td>\n","      <td>0.043750</td>\n","      <td>0.012868</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11098528</td>\n","      <td>884502</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>234</td>\n","      <td>166</td>\n","      <td>118</td>\n","      <td>981</td>\n","      <td>105</td>\n","      <td>17</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.00</td>\n","      <td>0.999999</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>28184</td>\n","      <td>2408</td>\n","      <td>930</td>\n","      <td>91</td>\n","      <td>118</td>\n","      <td>91</td>\n","      <td>8610</td>\n","      <td>688</td>\n","      <td>250</td>\n","      <td>152</td>\n","      <td>190</td>\n","      <td>144</td>\n","      <td>981</td>\n","      <td>105</td>\n","      <td>17</td>\n","      <td>234</td>\n","      <td>167</td>\n","      <td>121</td>\n","      <td>0.113937</td>\n","      <td>0.034807</td>\n","      <td>0.152616</td>\n","      <td>0.043605</td>\n","      <td>0.068000</td>\n","      <td>0.018280</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9892542</th>\n","      <td>12899525</td>\n","      <td>1556052</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>35</td>\n","      <td>89698</td>\n","      <td>169933</td>\n","      <td>-1</td>\n","      <td>13</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0.75</td>\n","      <td>0.500000</td>\n","      <td>0.25</td>\n","      <td>0.25</td>\n","      <td>374</td>\n","      <td>41</td>\n","      <td>16</td>\n","      <td>69602</td>\n","      <td>56648</td>\n","      <td>42786</td>\n","      <td>142</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>67165</td>\n","      <td>78051</td>\n","      <td>71202</td>\n","      <td>13</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>87131</td>\n","      <td>169937</td>\n","      <td>-1</td>\n","      <td>0.091549</td>\n","      <td>0.034759</td>\n","      <td>0.090909</td>\n","      <td>0.024390</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>9892543</th>\n","      <td>12899525</td>\n","      <td>500570</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>42</td>\n","      <td>2180</td>\n","      <td>631</td>\n","      <td>725</td>\n","      <td>261</td>\n","      <td>51</td>\n","      <td>7</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0.75</td>\n","      <td>0.500000</td>\n","      <td>0.25</td>\n","      <td>0.25</td>\n","      <td>7404</td>\n","      <td>1235</td>\n","      <td>342</td>\n","      <td>1273</td>\n","      <td>417</td>\n","      <td>621</td>\n","      <td>2879</td>\n","      <td>522</td>\n","      <td>135</td>\n","      <td>1191</td>\n","      <td>318</td>\n","      <td>489</td>\n","      <td>261</td>\n","      <td>51</td>\n","      <td>7</td>\n","      <td>2191</td>\n","      <td>639</td>\n","      <td>701</td>\n","      <td>0.090656</td>\n","      <td>0.035251</td>\n","      <td>0.097701</td>\n","      <td>0.041296</td>\n","      <td>0.051852</td>\n","      <td>0.020468</td>\n","    </tr>\n","    <tr>\n","      <th>9892544</th>\n","      <td>12899525</td>\n","      <td>1373578</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>43</td>\n","      <td>332706</td>\n","      <td>124681</td>\n","      <td>-1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0.75</td>\n","      <td>0.500000</td>\n","      <td>0.25</td>\n","      <td>0.25</td>\n","      <td>52</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>373850</td>\n","      <td>314923</td>\n","      <td>406989</td>\n","      <td>27</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>288523</td>\n","      <td>235878</td>\n","      <td>196449</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>299760</td>\n","      <td>123148</td>\n","      <td>-1</td>\n","      <td>0.111111</td>\n","      <td>0.057692</td>\n","      <td>0.333333</td>\n","      <td>0.166667</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>9892545</th>\n","      <td>12899525</td>\n","      <td>787412</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>48</td>\n","      <td>85291</td>\n","      <td>27285</td>\n","      <td>31628</td>\n","      <td>14</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0.75</td>\n","      <td>0.500000</td>\n","      <td>0.25</td>\n","      <td>0.25</td>\n","      <td>510</td>\n","      <td>75</td>\n","      <td>31</td>\n","      <td>50523</td>\n","      <td>28568</td>\n","      <td>21611</td>\n","      <td>120</td>\n","      <td>14</td>\n","      <td>7</td>\n","      <td>79787</td>\n","      <td>64324</td>\n","      <td>37254</td>\n","      <td>14</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>81767</td>\n","      <td>29421</td>\n","      <td>31627</td>\n","      <td>0.116667</td>\n","      <td>0.027451</td>\n","      <td>0.285714</td>\n","      <td>0.053333</td>\n","      <td>0.142857</td>\n","      <td>0.032258</td>\n","    </tr>\n","    <tr>\n","      <th>9892546</th>\n","      <td>12899525</td>\n","      <td>1357950</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>49</td>\n","      <td>150784</td>\n","      <td>169756</td>\n","      <td>-1</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>0.75</td>\n","      <td>0.500000</td>\n","      <td>0.25</td>\n","      <td>0.25</td>\n","      <td>274</td>\n","      <td>18</td>\n","      <td>3</td>\n","      <td>94711</td>\n","      <td>125051</td>\n","      <td>191076</td>\n","      <td>87</td>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>108121</td>\n","      <td>111462</td>\n","      <td>121158</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>148855</td>\n","      <td>169757</td>\n","      <td>-1</td>\n","      <td>0.091954</td>\n","      <td>0.029197</td>\n","      <td>0.125000</td>\n","      <td>0.055556</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9892547 rows × 53 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69597553-c541-4511-97f1-63283e808b2d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-69597553-c541-4511-97f1-63283e808b2d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-69597553-c541-4511-97f1-63283e808b2d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":13}],"source":["train"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"eY1bGfqgM-Oi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673488191257,"user_tz":-540,"elapsed":20,"user":{"displayName":"テッツォ","userId":"07789339878611604425"}},"outputId":"c05aa985-0293-48a4-81d3-4bef0062ee05"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["session                        int32\n","aid                            int32\n","score_click                  float32\n","score_cart                   float32\n","score_buy                    float32\n","score_click_only             float32\n","score_cart_only              float32\n","score_buy_only               float32\n","n_clicks_10                     int8\n","n_clicks_20                     int8\n","n_carts                         int8\n","n_buys                          int8\n","clicks_rank                    int32\n","carts_rank                     int32\n","orders_rank                    int32\n","clicks_count                   int32\n","carts_count                    int16\n","orders_count                   int16\n","y_clicks                        bool\n","y_carts                         bool\n","y_orders                        bool\n","session_action_count           int16\n","session_click_count            int16\n","session_cart_count             int16\n","session_order_count            int16\n","session_type_mean            float32\n","session_click_rate           float32\n","session_cart_rate            float32\n","session_order_rate           float32\n","clicks_count_4weeks            int32\n","carts_count_4weeks             int16\n","orders_count_4weeks            int16\n","clicks_rank_4weeks             int32\n","carts_rank_4weeks              int32\n","orders_rank_4weeks             int32\n","clicks_count_2weeks            int32\n","carts_count_2weeks             int16\n","orders_count_2weeks            int16\n","clicks_rank_2weeks             int32\n","carts_rank_2weeks              int32\n","orders_rank_2weeks             int32\n","clicks_count_1week             int32\n","carts_count_1week              int16\n","orders_count_1week             int16\n","clicks_rank_1week              int32\n","carts_rank_1week               int32\n","orders_rank_1week              int32\n","aid_clicks_count_rate_1_2    float32\n","aid_clicks_count_rate_1_4    float32\n","aid_carts_count_rate_1_2     float32\n","aid_carts_count_rate_1_4     float32\n","aid_orders_count_rate_1_2    float32\n","aid_orders_count_rate_1_4    float32\n","dtype: object"]},"metadata":{},"execution_count":14}],"source":["train.dtypes"]},{"cell_type":"markdown","metadata":{"id":"gOW-eeZAyZT8"},"source":["# Training & Inference"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"we5IplsR8tQ2","executionInfo":{"status":"ok","timestamp":1673488191257,"user_tz":-540,"elapsed":18,"user":{"displayName":"テッツォ","userId":"07789339878611604425"}}},"outputs":[],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import warnings\n","warnings.filterwarnings('ignore')\n","import random\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","import joblib\n","import itertools\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import KFold, train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","# optuna\n","if OPTUNA_FLAG:\n","    import optuna.integration.lightgbm as lgb\n","else:\n","    import lightgbm as lgb\n","\n","from itertools import combinations"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"yjzMNkv_MGj9","executionInfo":{"status":"ok","timestamp":1673488191258,"user_tz":-540,"elapsed":18,"user":{"displayName":"テッツォ","userId":"07789339878611604425"}}},"outputs":[],"source":["# old 0.0382316\n","# new 0.03822381002014941.\n","# new num=1000\n","if OPTUNA_FLAG:\n","    params = {\n","        'objective': 'binary',\n","        'metric': 'binary_logloss',  # Noneにした方がよさそう？\n","        'boosting': 'gbdt',\n","        'seed': 42,        \n","        'n_jobs': -1,\n","        'learning_rate': 0.05\n","        }\n","    # Create a numpy array to store out of folds predictions\n","    kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n","    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n","        print(' ')\n","        print('-'*50)\n","        print(f'Training fold {fold}...')\n","\n","        y_train, y_val = train[target].iloc[trn_ind], train[target].iloc[val_ind]\n","        train_tmp = train.drop(IGNORE_COL , axis=1)\n","        x_train, x_val = train_tmp.iloc[trn_ind], train_tmp.iloc[val_ind]\n","        del train_tmp\n","        gc.collect()\n","\n","        # under sampling\n","        x_train, y_train = negative_sampling(x_train, y_train, pos_neg_ratio)\n","\n","        lgb_train = lgb.Dataset(x_train, y_train)\n","        lgb_valid = lgb.Dataset(x_val, y_val)\n","        del x_train, y_train\n","        gc.collect()\n","\n","        #lgb_valid = lgb.Dataset(x_val, y_val)\n","        model = lgb.train(\n","            params = params,\n","            train_set = lgb_train,\n","            #num_boost_round = 10500,\n","            num_boost_round = 200,\n","            valid_sets = [lgb_train, lgb_valid],\n","            early_stopping_rounds = 20,\n","            verbose_eval = 10,\n","            )\n","        del lgb_train, lgb_valid\n","        gc.collect()\n","        break\n","    model.params"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"aTlbPCG4PKNS","executionInfo":{"status":"ok","timestamp":1673490529337,"user_tz":-540,"elapsed":573,"user":{"displayName":"テッツォ","userId":"07789339878611604425"}}},"outputs":[],"source":["if OPTUNA_FLAG:\n","    print(\"Optuna results: \",model.params)\n","# old params\n","'''\n","params =  {'objective': 'binary',\n"," 'metric': 'binary_logloss',\n"," 'boosting': 'gbdt',\n"," 'seed': 42,\n"," 'n_jobs': -1,\n"," 'feature_pre_filter': False,\n"," 'lambda_l1': 6.595370151657238,\n"," 'lambda_l2': 1.0592737233474818e-08,\n"," 'num_leaves': 255,\n"," 'feature_fraction': 1.0,\n"," 'bagging_fraction': 0.9703737428957173,\n"," 'bagging_freq': 2,\n"," 'min_child_samples': 20,\n"," #'learning_rate': 0.1\n","  'learning_rate': 0.05\n"," }\n"," '''\n","\n"," # new\n","params = {'objective': 'lambdarank',\n","          #'metric': 'ndcg',\n","          'metric': 'map',\n","          #'ndcg_eval_at': [10, 20, 50],\n","          'map_eval_at': [10, 20, 50],\n","          'boosting': 'gbdt',\n","          'seed': 42,\n","          'n_jobs': -1,\n","          'learning_rate': 0.05,\n","          'feature_pre_filter': False,\n","          'lambda_l1': 7.777864227173249,\n","          'lambda_l2': 0.000181104589355317,\n","          'num_leaves': 202,\n","          'feature_fraction': 0.8999999999999999,\n","          'bagging_fraction': 1.0,\n","          'bagging_freq': 0,\n","          'min_child_samples': 25\n","          }\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"3rIFfM_T-Uqc","executionInfo":{"status":"ok","timestamp":1673488191869,"user_tz":-540,"elapsed":10,"user":{"displayName":"テッツォ","userId":"07789339878611604425"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":146},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1673488191869,"user":{"displayName":"テッツォ","userId":"07789339878611604425"},"user_tz":-540},"id":"08bxnuie-YAA","outputId":"38751715-587c-4ffe-ee80-d3af0b413396"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\nsession = train['session']\\nunique_session = session.unique()\\nkfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\\nfor fold, (trn_group_ind, val_group_ind) in enumerate(kfold.split(unique_session)):\\n    print(' ')\\n    print('-'*50)\\n    print(f'Training fold {fold}...')\\n    # session単位で分割してKFoldする\\n    tr_groups, va_groups = unique_session[trn_group_ind], unique_session[val_group_ind]\\n    is_tr, is_va = session.isin(tr_groups), session.isin(va_groups)\\n\\n    # is_ir, is_va=Trueのindexを取得\\n    trn_ind, val_ind = is_tr[is_tr].index, is_va[is_va].index\\n\\n    y_train, y_val = train[target].iloc[trn_ind], train[target].iloc[val_ind]\\n    #train_tmp = train.drop(IGNORE_COL , axis=1)\\n    train_tmp = train.drop('aid' , axis=1)\\n    x_train, x_val = train_tmp.iloc[trn_ind], train_tmp.iloc[val_ind]\\n\\n\\n    # under sampling\\n    x_train, y_train = negative_sampling(x_train, y_train, pos_neg_ratio)\\n\\n    # queryの準備, sessionごとにsortする, lightGBMでranking metricsを使うときに必要\\n    query_list_train = x_train['session'].value_counts()\\n    #x_train = x_train.drop('session' , axis=1)\\n    query_list_train = query_list_train.sort_index()\\n\\n    query_list_valid = x_val['session'].value_counts()\\n    #x_val = x_val.drop('session' , axis=1)\\n    query_list_valid = query_list_valid.sort_index()\\n    break\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}],"source":["'''\n","session = train['session']\n","unique_session = session.unique()\n","kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n","for fold, (trn_group_ind, val_group_ind) in enumerate(kfold.split(unique_session)):\n","    print(' ')\n","    print('-'*50)\n","    print(f'Training fold {fold}...')\n","    # session単位で分割してKFoldする\n","    tr_groups, va_groups = unique_session[trn_group_ind], unique_session[val_group_ind]\n","    is_tr, is_va = session.isin(tr_groups), session.isin(va_groups)\n","\n","    # is_ir, is_va=Trueのindexを取得\n","    trn_ind, val_ind = is_tr[is_tr].index, is_va[is_va].index\n","\n","    y_train, y_val = train[target].iloc[trn_ind], train[target].iloc[val_ind]\n","    #train_tmp = train.drop(IGNORE_COL , axis=1)\n","    train_tmp = train.drop('aid' , axis=1)\n","    x_train, x_val = train_tmp.iloc[trn_ind], train_tmp.iloc[val_ind]\n","\n","\n","    # under sampling\n","    x_train, y_train = negative_sampling(x_train, y_train, pos_neg_ratio)\n","\n","    # queryの準備, sessionごとにsortする, lightGBMでranking metricsを使うときに必要\n","    query_list_train = x_train['session'].value_counts()\n","    #x_train = x_train.drop('session' , axis=1)\n","    query_list_train = query_list_train.sort_index()\n","\n","    query_list_valid = x_val['session'].value_counts()\n","    #x_val = x_val.drop('session' , axis=1)\n","    query_list_valid = query_list_valid.sort_index()\n","    break\n","'''"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1946340,"status":"ok","timestamp":1673492481514,"user":{"displayName":"テッツォ","userId":"07789339878611604425"},"user_tz":-540},"id":"E6kHtxYa93k_","outputId":"9ae2c3b3-0d90-40d6-fe7c-a95c65a95471"},"outputs":[{"output_type":"stream","name":"stdout","text":[" \n","--------------------------------------------------\n","Training fold 0...\n","before mean: 0.021826884561487306\n","under sampling....... 1 / 5\n","under sampling....... 2 / 5\n","under sampling....... 3 / 5\n","under sampling....... 4 / 5\n","under sampling....... 5 / 5\n","under sampling end\n","post proccess1\n","after mean: 0.025\n","Training until validation scores don't improve for 20 rounds.\n","[10]\ttraining's map@10: 0.78651\ttraining's map@20: 0.791172\ttraining's map@50: 0.793095\tvalid_1's map@10: 0.767671\tvalid_1's map@20: 0.772546\tvalid_1's map@50: 0.774667\n","[20]\ttraining's map@10: 0.789658\ttraining's map@20: 0.794274\ttraining's map@50: 0.796199\tvalid_1's map@10: 0.770091\tvalid_1's map@20: 0.774969\tvalid_1's map@50: 0.777138\n","[30]\ttraining's map@10: 0.792323\ttraining's map@20: 0.796836\ttraining's map@50: 0.798769\tvalid_1's map@10: 0.772177\tvalid_1's map@20: 0.77703\tvalid_1's map@50: 0.779171\n","[40]\ttraining's map@10: 0.794252\ttraining's map@20: 0.798785\ttraining's map@50: 0.800679\tvalid_1's map@10: 0.773281\tvalid_1's map@20: 0.778116\tvalid_1's map@50: 0.780267\n","[50]\ttraining's map@10: 0.796168\ttraining's map@20: 0.80069\ttraining's map@50: 0.802579\tvalid_1's map@10: 0.774526\tvalid_1's map@20: 0.779299\tvalid_1's map@50: 0.781484\n","[60]\ttraining's map@10: 0.798264\ttraining's map@20: 0.802769\ttraining's map@50: 0.804653\tvalid_1's map@10: 0.775681\tvalid_1's map@20: 0.78045\tvalid_1's map@50: 0.782625\n","[70]\ttraining's map@10: 0.800323\ttraining's map@20: 0.804808\ttraining's map@50: 0.806683\tvalid_1's map@10: 0.777582\tvalid_1's map@20: 0.782432\tvalid_1's map@50: 0.784586\n","[80]\ttraining's map@10: 0.802553\ttraining's map@20: 0.807017\ttraining's map@50: 0.808878\tvalid_1's map@10: 0.779125\tvalid_1's map@20: 0.784005\tvalid_1's map@50: 0.786122\n","[90]\ttraining's map@10: 0.804493\ttraining's map@20: 0.808972\ttraining's map@50: 0.810812\tvalid_1's map@10: 0.780287\tvalid_1's map@20: 0.785108\tvalid_1's map@50: 0.787244\n","[100]\ttraining's map@10: 0.806436\ttraining's map@20: 0.810917\ttraining's map@50: 0.81275\tvalid_1's map@10: 0.781231\tvalid_1's map@20: 0.786098\tvalid_1's map@50: 0.788217\n","[110]\ttraining's map@10: 0.808057\ttraining's map@20: 0.812514\ttraining's map@50: 0.814339\tvalid_1's map@10: 0.781943\tvalid_1's map@20: 0.786785\tvalid_1's map@50: 0.78892\n","[120]\ttraining's map@10: 0.80958\ttraining's map@20: 0.814023\ttraining's map@50: 0.815838\tvalid_1's map@10: 0.782807\tvalid_1's map@20: 0.787678\tvalid_1's map@50: 0.78981\n","[130]\ttraining's map@10: 0.810908\ttraining's map@20: 0.815332\ttraining's map@50: 0.817125\tvalid_1's map@10: 0.783091\tvalid_1's map@20: 0.787935\tvalid_1's map@50: 0.790078\n","[140]\ttraining's map@10: 0.812051\ttraining's map@20: 0.816481\ttraining's map@50: 0.818256\tvalid_1's map@10: 0.783635\tvalid_1's map@20: 0.788474\tvalid_1's map@50: 0.7906\n","[150]\ttraining's map@10: 0.81317\ttraining's map@20: 0.817569\ttraining's map@50: 0.819336\tvalid_1's map@10: 0.784115\tvalid_1's map@20: 0.788941\tvalid_1's map@50: 0.791089\n","[160]\ttraining's map@10: 0.814231\ttraining's map@20: 0.818617\ttraining's map@50: 0.82038\tvalid_1's map@10: 0.784309\tvalid_1's map@20: 0.789119\tvalid_1's map@50: 0.791269\n","[170]\ttraining's map@10: 0.815332\ttraining's map@20: 0.819692\ttraining's map@50: 0.821445\tvalid_1's map@10: 0.784705\tvalid_1's map@20: 0.789511\tvalid_1's map@50: 0.791669\n","[180]\ttraining's map@10: 0.816229\ttraining's map@20: 0.820604\ttraining's map@50: 0.822344\tvalid_1's map@10: 0.784827\tvalid_1's map@20: 0.789668\tvalid_1's map@50: 0.791829\n","[190]\ttraining's map@10: 0.817182\ttraining's map@20: 0.821549\ttraining's map@50: 0.82328\tvalid_1's map@10: 0.784859\tvalid_1's map@20: 0.789682\tvalid_1's map@50: 0.791833\n","[200]\ttraining's map@10: 0.818133\ttraining's map@20: 0.82249\ttraining's map@50: 0.824217\tvalid_1's map@10: 0.785302\tvalid_1's map@20: 0.79011\tvalid_1's map@50: 0.792253\n","[210]\ttraining's map@10: 0.818908\ttraining's map@20: 0.82326\ttraining's map@50: 0.824977\tvalid_1's map@10: 0.785383\tvalid_1's map@20: 0.790169\tvalid_1's map@50: 0.792327\n","[220]\ttraining's map@10: 0.81978\ttraining's map@20: 0.824107\ttraining's map@50: 0.825812\tvalid_1's map@10: 0.785363\tvalid_1's map@20: 0.790169\tvalid_1's map@50: 0.79232\n","Early stopping, best iteration is:\n","[205]\ttraining's map@10: 0.818546\ttraining's map@20: 0.822899\ttraining's map@50: 0.824619\tvalid_1's map@10: 0.785524\tvalid_1's map@20: 0.790326\tvalid_1's map@50: 0.792477\n","train pred i= 0\n","train pred i= 1\n","train pred i= 2\n","train pred i= 3\n","train pred i= 4\n"," \n","--------------------------------------------------\n","Training fold 1...\n","before mean: 0.021870624160050357\n","under sampling....... 1 / 5\n","under sampling....... 2 / 5\n","under sampling....... 3 / 5\n","under sampling....... 4 / 5\n","under sampling....... 5 / 5\n","under sampling end\n","post proccess1\n","after mean: 0.025\n","Training until validation scores don't improve for 20 rounds.\n","[10]\ttraining's map@10: 0.784852\ttraining's map@20: 0.78946\ttraining's map@50: 0.791419\tvalid_1's map@10: 0.772344\tvalid_1's map@20: 0.77734\tvalid_1's map@50: 0.779352\n","[20]\ttraining's map@10: 0.78772\ttraining's map@20: 0.79233\ttraining's map@50: 0.794292\tvalid_1's map@10: 0.774728\tvalid_1's map@20: 0.779661\tvalid_1's map@50: 0.781688\n","[30]\ttraining's map@10: 0.790129\ttraining's map@20: 0.794679\ttraining's map@50: 0.796638\tvalid_1's map@10: 0.777312\tvalid_1's map@20: 0.782078\tvalid_1's map@50: 0.78412\n","[40]\ttraining's map@10: 0.792427\ttraining's map@20: 0.796956\ttraining's map@50: 0.798903\tvalid_1's map@10: 0.779136\tvalid_1's map@20: 0.783918\tvalid_1's map@50: 0.785946\n","[50]\ttraining's map@10: 0.794256\ttraining's map@20: 0.798838\ttraining's map@50: 0.80076\tvalid_1's map@10: 0.779978\tvalid_1's map@20: 0.784732\tvalid_1's map@50: 0.786782\n","[60]\ttraining's map@10: 0.796737\ttraining's map@20: 0.801294\ttraining's map@50: 0.803199\tvalid_1's map@10: 0.781598\tvalid_1's map@20: 0.786405\tvalid_1's map@50: 0.788428\n","[70]\ttraining's map@10: 0.799217\ttraining's map@20: 0.803763\ttraining's map@50: 0.805654\tvalid_1's map@10: 0.782815\tvalid_1's map@20: 0.787615\tvalid_1's map@50: 0.789632\n","[80]\ttraining's map@10: 0.801588\ttraining's map@20: 0.806132\ttraining's map@50: 0.80801\tvalid_1's map@10: 0.783769\tvalid_1's map@20: 0.788513\tvalid_1's map@50: 0.79052\n","[90]\ttraining's map@10: 0.803692\ttraining's map@20: 0.808231\ttraining's map@50: 0.8101\tvalid_1's map@10: 0.784924\tvalid_1's map@20: 0.789655\tvalid_1's map@50: 0.791681\n","[100]\ttraining's map@10: 0.805441\ttraining's map@20: 0.809963\ttraining's map@50: 0.811808\tvalid_1's map@10: 0.785615\tvalid_1's map@20: 0.790345\tvalid_1's map@50: 0.792353\n","[110]\ttraining's map@10: 0.8069\ttraining's map@20: 0.811379\ttraining's map@50: 0.813228\tvalid_1's map@10: 0.785927\tvalid_1's map@20: 0.790672\tvalid_1's map@50: 0.792675\n","[120]\ttraining's map@10: 0.808317\ttraining's map@20: 0.812798\ttraining's map@50: 0.814646\tvalid_1's map@10: 0.786472\tvalid_1's map@20: 0.791215\tvalid_1's map@50: 0.793222\n","[130]\ttraining's map@10: 0.809756\ttraining's map@20: 0.814229\ttraining's map@50: 0.816055\tvalid_1's map@10: 0.786671\tvalid_1's map@20: 0.791409\tvalid_1's map@50: 0.79342\n","[140]\ttraining's map@10: 0.811106\ttraining's map@20: 0.815538\ttraining's map@50: 0.817358\tvalid_1's map@10: 0.787096\tvalid_1's map@20: 0.791816\tvalid_1's map@50: 0.793824\n","[150]\ttraining's map@10: 0.81218\ttraining's map@20: 0.816591\ttraining's map@50: 0.818396\tvalid_1's map@10: 0.787355\tvalid_1's map@20: 0.792056\tvalid_1's map@50: 0.794058\n","[160]\ttraining's map@10: 0.813133\ttraining's map@20: 0.817535\ttraining's map@50: 0.819335\tvalid_1's map@10: 0.787462\tvalid_1's map@20: 0.792177\tvalid_1's map@50: 0.794183\n","[170]\ttraining's map@10: 0.81414\ttraining's map@20: 0.818521\ttraining's map@50: 0.820307\tvalid_1's map@10: 0.787608\tvalid_1's map@20: 0.79232\tvalid_1's map@50: 0.79434\n","[180]\ttraining's map@10: 0.815143\ttraining's map@20: 0.819519\ttraining's map@50: 0.821295\tvalid_1's map@10: 0.787789\tvalid_1's map@20: 0.79252\tvalid_1's map@50: 0.794536\n","[190]\ttraining's map@10: 0.816105\ttraining's map@20: 0.820481\ttraining's map@50: 0.822246\tvalid_1's map@10: 0.788037\tvalid_1's map@20: 0.792797\tvalid_1's map@50: 0.794808\n","[200]\ttraining's map@10: 0.816839\ttraining's map@20: 0.821218\ttraining's map@50: 0.822978\tvalid_1's map@10: 0.78813\tvalid_1's map@20: 0.792834\tvalid_1's map@50: 0.794845\n","[210]\ttraining's map@10: 0.817693\ttraining's map@20: 0.822038\ttraining's map@50: 0.823795\tvalid_1's map@10: 0.788266\tvalid_1's map@20: 0.792999\tvalid_1's map@50: 0.794994\n","[220]\ttraining's map@10: 0.818579\ttraining's map@20: 0.822908\ttraining's map@50: 0.824661\tvalid_1's map@10: 0.788498\tvalid_1's map@20: 0.793223\tvalid_1's map@50: 0.795214\n","[230]\ttraining's map@10: 0.819566\ttraining's map@20: 0.823878\ttraining's map@50: 0.825626\tvalid_1's map@10: 0.788304\tvalid_1's map@20: 0.793022\tvalid_1's map@50: 0.795012\n","[240]\ttraining's map@10: 0.820351\ttraining's map@20: 0.824659\ttraining's map@50: 0.8264\tvalid_1's map@10: 0.788652\tvalid_1's map@20: 0.793394\tvalid_1's map@50: 0.795367\n","[250]\ttraining's map@10: 0.821241\ttraining's map@20: 0.825532\ttraining's map@50: 0.827262\tvalid_1's map@10: 0.788737\tvalid_1's map@20: 0.793481\tvalid_1's map@50: 0.795459\n","[260]\ttraining's map@10: 0.822073\ttraining's map@20: 0.826366\ttraining's map@50: 0.82809\tvalid_1's map@10: 0.788849\tvalid_1's map@20: 0.793593\tvalid_1's map@50: 0.795576\n","[270]\ttraining's map@10: 0.822932\ttraining's map@20: 0.827217\ttraining's map@50: 0.828922\tvalid_1's map@10: 0.78908\tvalid_1's map@20: 0.7938\tvalid_1's map@50: 0.795793\n","[280]\ttraining's map@10: 0.823851\ttraining's map@20: 0.828126\ttraining's map@50: 0.829828\tvalid_1's map@10: 0.78921\tvalid_1's map@20: 0.793935\tvalid_1's map@50: 0.795927\n","[290]\ttraining's map@10: 0.824825\ttraining's map@20: 0.829099\ttraining's map@50: 0.830793\tvalid_1's map@10: 0.789079\tvalid_1's map@20: 0.79381\tvalid_1's map@50: 0.795801\n","Early stopping, best iteration is:\n","[279]\ttraining's map@10: 0.823734\ttraining's map@20: 0.828014\ttraining's map@50: 0.829716\tvalid_1's map@10: 0.789231\tvalid_1's map@20: 0.793961\tvalid_1's map@50: 0.795948\n","train pred i= 0\n","train pred i= 1\n","train pred i= 2\n","train pred i= 3\n","train pred i= 4\n"," \n","--------------------------------------------------\n","Training fold 2...\n","before mean: 0.02185888619292898\n","under sampling....... 1 / 5\n","under sampling....... 2 / 5\n","under sampling....... 3 / 5\n","under sampling....... 4 / 5\n","under sampling....... 5 / 5\n","under sampling end\n","post proccess1\n","after mean: 0.025\n","Training until validation scores don't improve for 20 rounds.\n","[10]\ttraining's map@10: 0.785505\ttraining's map@20: 0.790176\ttraining's map@50: 0.792099\tvalid_1's map@10: 0.772173\tvalid_1's map@20: 0.776967\tvalid_1's map@50: 0.778989\n","[20]\ttraining's map@10: 0.787968\ttraining's map@20: 0.792601\ttraining's map@50: 0.794558\tvalid_1's map@10: 0.774535\tvalid_1's map@20: 0.779171\tvalid_1's map@50: 0.781223\n","[30]\ttraining's map@10: 0.790403\ttraining's map@20: 0.795\ttraining's map@50: 0.796955\tvalid_1's map@10: 0.776629\tvalid_1's map@20: 0.781258\tvalid_1's map@50: 0.78328\n","[40]\ttraining's map@10: 0.792583\ttraining's map@20: 0.797165\ttraining's map@50: 0.799104\tvalid_1's map@10: 0.778097\tvalid_1's map@20: 0.782683\tvalid_1's map@50: 0.784714\n","[50]\ttraining's map@10: 0.795066\ttraining's map@20: 0.799635\ttraining's map@50: 0.801556\tvalid_1's map@10: 0.779818\tvalid_1's map@20: 0.784361\tvalid_1's map@50: 0.786393\n","[60]\ttraining's map@10: 0.797406\ttraining's map@20: 0.801969\ttraining's map@50: 0.803876\tvalid_1's map@10: 0.781334\tvalid_1's map@20: 0.785869\tvalid_1's map@50: 0.78788\n","[70]\ttraining's map@10: 0.799555\ttraining's map@20: 0.804094\ttraining's map@50: 0.805987\tvalid_1's map@10: 0.78221\tvalid_1's map@20: 0.786709\tvalid_1's map@50: 0.788713\n","[80]\ttraining's map@10: 0.801563\ttraining's map@20: 0.806083\ttraining's map@50: 0.807963\tvalid_1's map@10: 0.783363\tvalid_1's map@20: 0.787856\tvalid_1's map@50: 0.789863\n","[90]\ttraining's map@10: 0.803624\ttraining's map@20: 0.808142\ttraining's map@50: 0.809999\tvalid_1's map@10: 0.784496\tvalid_1's map@20: 0.788993\tvalid_1's map@50: 0.790988\n","[100]\ttraining's map@10: 0.8054\ttraining's map@20: 0.809899\ttraining's map@50: 0.811746\tvalid_1's map@10: 0.785303\tvalid_1's map@20: 0.789789\tvalid_1's map@50: 0.791795\n","[110]\ttraining's map@10: 0.807139\ttraining's map@20: 0.811623\ttraining's map@50: 0.813459\tvalid_1's map@10: 0.786053\tvalid_1's map@20: 0.790494\tvalid_1's map@50: 0.792503\n","[120]\ttraining's map@10: 0.808665\ttraining's map@20: 0.813139\ttraining's map@50: 0.814963\tvalid_1's map@10: 0.786647\tvalid_1's map@20: 0.791111\tvalid_1's map@50: 0.793109\n","[130]\ttraining's map@10: 0.809867\ttraining's map@20: 0.814336\ttraining's map@50: 0.816151\tvalid_1's map@10: 0.787226\tvalid_1's map@20: 0.7917\tvalid_1's map@50: 0.793713\n","[140]\ttraining's map@10: 0.81114\ttraining's map@20: 0.815616\ttraining's map@50: 0.81742\tvalid_1's map@10: 0.787471\tvalid_1's map@20: 0.791907\tvalid_1's map@50: 0.793924\n","[150]\ttraining's map@10: 0.812252\ttraining's map@20: 0.81671\ttraining's map@50: 0.818493\tvalid_1's map@10: 0.787719\tvalid_1's map@20: 0.792153\tvalid_1's map@50: 0.794186\n","[160]\ttraining's map@10: 0.813285\ttraining's map@20: 0.817719\ttraining's map@50: 0.819495\tvalid_1's map@10: 0.788038\tvalid_1's map@20: 0.792484\tvalid_1's map@50: 0.794505\n","[170]\ttraining's map@10: 0.814197\ttraining's map@20: 0.818613\ttraining's map@50: 0.820375\tvalid_1's map@10: 0.788365\tvalid_1's map@20: 0.792801\tvalid_1's map@50: 0.79482\n","[180]\ttraining's map@10: 0.815085\ttraining's map@20: 0.819473\ttraining's map@50: 0.82123\tvalid_1's map@10: 0.788823\tvalid_1's map@20: 0.793246\tvalid_1's map@50: 0.795257\n","[190]\ttraining's map@10: 0.816085\ttraining's map@20: 0.820468\ttraining's map@50: 0.822219\tvalid_1's map@10: 0.788879\tvalid_1's map@20: 0.793355\tvalid_1's map@50: 0.795344\n","[200]\ttraining's map@10: 0.817022\ttraining's map@20: 0.821382\ttraining's map@50: 0.823133\tvalid_1's map@10: 0.789029\tvalid_1's map@20: 0.793501\tvalid_1's map@50: 0.795487\n","[210]\ttraining's map@10: 0.817799\ttraining's map@20: 0.822132\ttraining's map@50: 0.823869\tvalid_1's map@10: 0.78923\tvalid_1's map@20: 0.793701\tvalid_1's map@50: 0.795689\n","[220]\ttraining's map@10: 0.818571\ttraining's map@20: 0.822904\ttraining's map@50: 0.824628\tvalid_1's map@10: 0.789207\tvalid_1's map@20: 0.793682\tvalid_1's map@50: 0.795656\n","Early stopping, best iteration is:\n","[208]\ttraining's map@10: 0.81763\ttraining's map@20: 0.821969\ttraining's map@50: 0.823706\tvalid_1's map@10: 0.789366\tvalid_1's map@20: 0.793838\tvalid_1's map@50: 0.79582\n","train pred i= 0\n","train pred i= 1\n","train pred i= 2\n","train pred i= 3\n","train pred i= 4\n"," \n","--------------------------------------------------\n","Training fold 3...\n","before mean: 0.021824143620629597\n","under sampling....... 1 / 5\n","under sampling....... 2 / 5\n","under sampling....... 3 / 5\n","under sampling....... 4 / 5\n","under sampling....... 5 / 5\n","under sampling end\n","post proccess1\n","after mean: 0.025\n","Training until validation scores don't improve for 20 rounds.\n","[10]\ttraining's map@10: 0.786696\ttraining's map@20: 0.791269\ttraining's map@50: 0.793212\tvalid_1's map@10: 0.767393\tvalid_1's map@20: 0.772591\tvalid_1's map@50: 0.774731\n","[20]\ttraining's map@10: 0.789421\ttraining's map@20: 0.793935\ttraining's map@50: 0.795871\tvalid_1's map@10: 0.769957\tvalid_1's map@20: 0.775029\tvalid_1's map@50: 0.777162\n","[30]\ttraining's map@10: 0.791764\ttraining's map@20: 0.79621\ttraining's map@50: 0.798139\tvalid_1's map@10: 0.77178\tvalid_1's map@20: 0.776813\tvalid_1's map@50: 0.778932\n","[40]\ttraining's map@10: 0.79392\ttraining's map@20: 0.798335\ttraining's map@50: 0.800253\tvalid_1's map@10: 0.772858\tvalid_1's map@20: 0.777925\tvalid_1's map@50: 0.780036\n","[50]\ttraining's map@10: 0.796089\ttraining's map@20: 0.800518\ttraining's map@50: 0.802432\tvalid_1's map@10: 0.774322\tvalid_1's map@20: 0.779425\tvalid_1's map@50: 0.781523\n","[60]\ttraining's map@10: 0.798593\ttraining's map@20: 0.803004\ttraining's map@50: 0.80491\tvalid_1's map@10: 0.775472\tvalid_1's map@20: 0.780528\tvalid_1's map@50: 0.782656\n","[70]\ttraining's map@10: 0.801024\ttraining's map@20: 0.80545\ttraining's map@50: 0.807348\tvalid_1's map@10: 0.776811\tvalid_1's map@20: 0.781876\tvalid_1's map@50: 0.783996\n","[80]\ttraining's map@10: 0.803194\ttraining's map@20: 0.807594\ttraining's map@50: 0.809486\tvalid_1's map@10: 0.777663\tvalid_1's map@20: 0.782719\tvalid_1's map@50: 0.784846\n","[90]\ttraining's map@10: 0.805198\ttraining's map@20: 0.809593\ttraining's map@50: 0.81148\tvalid_1's map@10: 0.778781\tvalid_1's map@20: 0.783838\tvalid_1's map@50: 0.78594\n","[100]\ttraining's map@10: 0.807005\ttraining's map@20: 0.811408\ttraining's map@50: 0.813274\tvalid_1's map@10: 0.779266\tvalid_1's map@20: 0.784323\tvalid_1's map@50: 0.786421\n","[110]\ttraining's map@10: 0.808434\ttraining's map@20: 0.812839\ttraining's map@50: 0.81469\tvalid_1's map@10: 0.780201\tvalid_1's map@20: 0.785197\tvalid_1's map@50: 0.787274\n","[120]\ttraining's map@10: 0.809716\ttraining's map@20: 0.814129\ttraining's map@50: 0.815969\tvalid_1's map@10: 0.780689\tvalid_1's map@20: 0.785654\tvalid_1's map@50: 0.787739\n","[130]\ttraining's map@10: 0.81086\ttraining's map@20: 0.815247\ttraining's map@50: 0.81707\tvalid_1's map@10: 0.780934\tvalid_1's map@20: 0.785893\tvalid_1's map@50: 0.787974\n","[140]\ttraining's map@10: 0.812048\ttraining's map@20: 0.81643\ttraining's map@50: 0.818236\tvalid_1's map@10: 0.781456\tvalid_1's map@20: 0.786424\tvalid_1's map@50: 0.788513\n","[150]\ttraining's map@10: 0.813046\ttraining's map@20: 0.817425\ttraining's map@50: 0.819217\tvalid_1's map@10: 0.782012\tvalid_1's map@20: 0.78694\tvalid_1's map@50: 0.789024\n","[160]\ttraining's map@10: 0.81423\ttraining's map@20: 0.818587\ttraining's map@50: 0.820366\tvalid_1's map@10: 0.78227\tvalid_1's map@20: 0.78722\tvalid_1's map@50: 0.789292\n","[170]\ttraining's map@10: 0.815263\ttraining's map@20: 0.819592\ttraining's map@50: 0.821369\tvalid_1's map@10: 0.782578\tvalid_1's map@20: 0.787499\tvalid_1's map@50: 0.789556\n","[180]\ttraining's map@10: 0.816149\ttraining's map@20: 0.820483\ttraining's map@50: 0.822246\tvalid_1's map@10: 0.782841\tvalid_1's map@20: 0.787755\tvalid_1's map@50: 0.789816\n","[190]\ttraining's map@10: 0.817084\ttraining's map@20: 0.821405\ttraining's map@50: 0.823159\tvalid_1's map@10: 0.78284\tvalid_1's map@20: 0.787788\tvalid_1's map@50: 0.789826\n","[200]\ttraining's map@10: 0.817955\ttraining's map@20: 0.82229\ttraining's map@50: 0.824029\tvalid_1's map@10: 0.783108\tvalid_1's map@20: 0.788062\tvalid_1's map@50: 0.790095\n","[210]\ttraining's map@10: 0.818732\ttraining's map@20: 0.823061\ttraining's map@50: 0.824786\tvalid_1's map@10: 0.783148\tvalid_1's map@20: 0.788102\tvalid_1's map@50: 0.79014\n","[220]\ttraining's map@10: 0.819508\ttraining's map@20: 0.82381\ttraining's map@50: 0.825528\tvalid_1's map@10: 0.783369\tvalid_1's map@20: 0.788329\tvalid_1's map@50: 0.790369\n","[230]\ttraining's map@10: 0.82025\ttraining's map@20: 0.824537\ttraining's map@50: 0.826247\tvalid_1's map@10: 0.783557\tvalid_1's map@20: 0.788511\tvalid_1's map@50: 0.790545\n","[240]\ttraining's map@10: 0.820906\ttraining's map@20: 0.825189\ttraining's map@50: 0.826886\tvalid_1's map@10: 0.78358\tvalid_1's map@20: 0.788517\tvalid_1's map@50: 0.790556\n","[250]\ttraining's map@10: 0.821678\ttraining's map@20: 0.825944\ttraining's map@50: 0.827633\tvalid_1's map@10: 0.783523\tvalid_1's map@20: 0.78847\tvalid_1's map@50: 0.790517\n","[260]\ttraining's map@10: 0.822494\ttraining's map@20: 0.82676\ttraining's map@50: 0.828433\tvalid_1's map@10: 0.783816\tvalid_1's map@20: 0.788741\tvalid_1's map@50: 0.790789\n","[270]\ttraining's map@10: 0.823208\ttraining's map@20: 0.827463\ttraining's map@50: 0.829128\tvalid_1's map@10: 0.783981\tvalid_1's map@20: 0.788919\tvalid_1's map@50: 0.790971\n","[280]\ttraining's map@10: 0.823798\ttraining's map@20: 0.828059\ttraining's map@50: 0.829707\tvalid_1's map@10: 0.784138\tvalid_1's map@20: 0.789088\tvalid_1's map@50: 0.79113\n","[290]\ttraining's map@10: 0.824476\ttraining's map@20: 0.828726\ttraining's map@50: 0.830373\tvalid_1's map@10: 0.784115\tvalid_1's map@20: 0.78904\tvalid_1's map@50: 0.791094\n","[300]\ttraining's map@10: 0.825337\ttraining's map@20: 0.829557\ttraining's map@50: 0.831195\tvalid_1's map@10: 0.784213\tvalid_1's map@20: 0.789134\tvalid_1's map@50: 0.791185\n","[310]\ttraining's map@10: 0.826144\ttraining's map@20: 0.830351\ttraining's map@50: 0.83198\tvalid_1's map@10: 0.784465\tvalid_1's map@20: 0.789372\tvalid_1's map@50: 0.791418\n","[320]\ttraining's map@10: 0.82696\ttraining's map@20: 0.831159\ttraining's map@50: 0.832781\tvalid_1's map@10: 0.784482\tvalid_1's map@20: 0.789415\tvalid_1's map@50: 0.791464\n","[330]\ttraining's map@10: 0.82772\ttraining's map@20: 0.831919\ttraining's map@50: 0.833533\tvalid_1's map@10: 0.784245\tvalid_1's map@20: 0.789196\tvalid_1's map@50: 0.791242\n","Early stopping, best iteration is:\n","[318]\ttraining's map@10: 0.82677\ttraining's map@20: 0.83097\ttraining's map@50: 0.83259\tvalid_1's map@10: 0.784555\tvalid_1's map@20: 0.789487\tvalid_1's map@50: 0.791537\n","train pred i= 0\n","train pred i= 1\n","train pred i= 2\n","train pred i= 3\n","train pred i= 4\n"," \n","--------------------------------------------------\n","Training fold 4...\n","before mean: 0.02187090168569247\n","under sampling....... 1 / 5\n","under sampling....... 2 / 5\n","under sampling....... 3 / 5\n","under sampling....... 4 / 5\n","under sampling....... 5 / 5\n","under sampling end\n","post proccess1\n","after mean: 0.025\n","Training until validation scores don't improve for 20 rounds.\n","[10]\ttraining's map@10: 0.785651\ttraining's map@20: 0.79028\ttraining's map@50: 0.792228\tvalid_1's map@10: 0.771726\tvalid_1's map@20: 0.776543\tvalid_1's map@50: 0.778576\n","[20]\ttraining's map@10: 0.788378\ttraining's map@20: 0.79295\ttraining's map@50: 0.794895\tvalid_1's map@10: 0.77377\tvalid_1's map@20: 0.77867\tvalid_1's map@50: 0.780715\n","[30]\ttraining's map@10: 0.7906\ttraining's map@20: 0.795134\ttraining's map@50: 0.79709\tvalid_1's map@10: 0.775345\tvalid_1's map@20: 0.780126\tvalid_1's map@50: 0.782165\n","[40]\ttraining's map@10: 0.792746\ttraining's map@20: 0.797283\ttraining's map@50: 0.799217\tvalid_1's map@10: 0.777284\tvalid_1's map@20: 0.781949\tvalid_1's map@50: 0.783982\n","[50]\ttraining's map@10: 0.795085\ttraining's map@20: 0.799629\ttraining's map@50: 0.801561\tvalid_1's map@10: 0.77865\tvalid_1's map@20: 0.783302\tvalid_1's map@50: 0.785307\n","[60]\ttraining's map@10: 0.797398\ttraining's map@20: 0.801948\ttraining's map@50: 0.803862\tvalid_1's map@10: 0.780305\tvalid_1's map@20: 0.784987\tvalid_1's map@50: 0.786986\n","[70]\ttraining's map@10: 0.799519\ttraining's map@20: 0.804069\ttraining's map@50: 0.805977\tvalid_1's map@10: 0.781701\tvalid_1's map@20: 0.786351\tvalid_1's map@50: 0.788355\n","[80]\ttraining's map@10: 0.801576\ttraining's map@20: 0.806133\ttraining's map@50: 0.808031\tvalid_1's map@10: 0.782614\tvalid_1's map@20: 0.787319\tvalid_1's map@50: 0.789292\n","[90]\ttraining's map@10: 0.803561\ttraining's map@20: 0.808085\ttraining's map@50: 0.809968\tvalid_1's map@10: 0.783614\tvalid_1's map@20: 0.78834\tvalid_1's map@50: 0.790295\n","[100]\ttraining's map@10: 0.805366\ttraining's map@20: 0.809884\ttraining's map@50: 0.811758\tvalid_1's map@10: 0.78449\tvalid_1's map@20: 0.78916\tvalid_1's map@50: 0.791104\n","[110]\ttraining's map@10: 0.806993\ttraining's map@20: 0.81149\ttraining's map@50: 0.813355\tvalid_1's map@10: 0.785029\tvalid_1's map@20: 0.789626\tvalid_1's map@50: 0.791582\n","[120]\ttraining's map@10: 0.808306\ttraining's map@20: 0.81281\ttraining's map@50: 0.814661\tvalid_1's map@10: 0.785645\tvalid_1's map@20: 0.790255\tvalid_1's map@50: 0.792218\n","[130]\ttraining's map@10: 0.809733\ttraining's map@20: 0.814213\ttraining's map@50: 0.816071\tvalid_1's map@10: 0.786039\tvalid_1's map@20: 0.790609\tvalid_1's map@50: 0.79256\n","[140]\ttraining's map@10: 0.811001\ttraining's map@20: 0.815473\ttraining's map@50: 0.817313\tvalid_1's map@10: 0.786339\tvalid_1's map@20: 0.790971\tvalid_1's map@50: 0.792927\n","[150]\ttraining's map@10: 0.812142\ttraining's map@20: 0.816603\ttraining's map@50: 0.818435\tvalid_1's map@10: 0.786539\tvalid_1's map@20: 0.791181\tvalid_1's map@50: 0.79313\n","[160]\ttraining's map@10: 0.81322\ttraining's map@20: 0.817665\ttraining's map@50: 0.819488\tvalid_1's map@10: 0.786726\tvalid_1's map@20: 0.791402\tvalid_1's map@50: 0.793343\n","[170]\ttraining's map@10: 0.814307\ttraining's map@20: 0.818732\ttraining's map@50: 0.82054\tvalid_1's map@10: 0.786769\tvalid_1's map@20: 0.791418\tvalid_1's map@50: 0.79334\n","[180]\ttraining's map@10: 0.815283\ttraining's map@20: 0.819702\ttraining's map@50: 0.821493\tvalid_1's map@10: 0.786982\tvalid_1's map@20: 0.791611\tvalid_1's map@50: 0.793531\n","[190]\ttraining's map@10: 0.816151\ttraining's map@20: 0.820573\ttraining's map@50: 0.822353\tvalid_1's map@10: 0.787312\tvalid_1's map@20: 0.791979\tvalid_1's map@50: 0.793902\n","[200]\ttraining's map@10: 0.817156\ttraining's map@20: 0.821561\ttraining's map@50: 0.823328\tvalid_1's map@10: 0.787556\tvalid_1's map@20: 0.792219\tvalid_1's map@50: 0.794155\n","[210]\ttraining's map@10: 0.817995\ttraining's map@20: 0.822393\ttraining's map@50: 0.824151\tvalid_1's map@10: 0.787427\tvalid_1's map@20: 0.792125\tvalid_1's map@50: 0.794058\n","Early stopping, best iteration is:\n","[198]\ttraining's map@10: 0.816973\ttraining's map@20: 0.821369\ttraining's map@50: 0.823141\tvalid_1's map@10: 0.787687\tvalid_1's map@20: 0.792344\tvalid_1's map@50: 0.794282\n","train pred i= 0\n","train pred i= 1\n","train pred i= 2\n","train pred i= 3\n","train pred i= 4\n"]}],"source":["\n","# Create a numpy array to store out of folds predictions\n","oof_predictions = np.zeros(len(train))\n","session = train['session']\n","unique_session = session.unique()\n","\n","kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n","for fold, (trn_group_ind, val_group_ind) in enumerate(kfold.split(unique_session)):\n","    print(' ')\n","    print('-'*50)\n","    print(f'Training fold {fold}...')\n","    # session単位で分割してKFoldする\n","    tr_groups, va_groups = unique_session[trn_group_ind], unique_session[val_group_ind]\n","    is_tr, is_va = session.isin(tr_groups), session.isin(va_groups)\n","    del tr_groups, va_groups\n","    gc.collect()\n","    # is_ir, is_va=Trueのindexを取得\n","    trn_ind, val_ind = is_tr[is_tr].index, is_va[is_va].index\n","    del is_tr, is_va\n","    gc.collect()\n","\n","    y_train, y_val = train[target].iloc[trn_ind], train[target].iloc[val_ind]\n","    #train_tmp = train.drop(IGNORE_COL , axis=1)\n","    train_tmp = train.drop(TARGET_COL , axis=1)\n","    train_tmp = train_tmp.drop('aid' , axis=1)\n","    x_train, x_val = train_tmp.iloc[trn_ind], train_tmp.iloc[val_ind]\n","\n","    del train_tmp\n","    gc.collect()\n","\n","    # under sampling\n","    x_train, y_train = negative_sampling(x_train, y_train, pos_neg_ratio)\n","\n","    # queryの準備, sessionごとにsortする, lightGBMでranking metricsを使うときに必要\n","    query_list_train = x_train['session'].value_counts()\n","    x_train = x_train.drop('session' , axis=1)\n","    query_list_train = query_list_train.sort_index()\n","\n","    query_list_valid = x_val['session'].value_counts()\n","    x_val = x_val.drop('session' , axis=1)\n","    query_list_valid = query_list_valid.sort_index()\n","\n","    lgb_train = lgb.Dataset(x_train, y_train, group=query_list_train)\n","    lgb_valid = lgb.Dataset(x_val, y_val, group=query_list_valid)\n","\n","    del x_train, y_train\n","    gc.collect()\n","\n","    model = lgb.train(\n","        params = params,\n","        train_set = lgb_train,\n","        #num_boost_round = 10500,\n","        num_boost_round = 1000,\n","        valid_sets = [lgb_train, lgb_valid],\n","        early_stopping_rounds = 20,\n","        verbose_eval = 10,\n","        )\n","    del lgb_train, lgb_valid\n","    gc.collect()\n","\n","\n","    # Save best model\n","    joblib.dump(model, f'{base_path}/otto/otto_lgbm_fold{fold}_{TYPE_MODE}.pkl')\n","    # Predict validation\n","    # でかいので分割してpredict\n","    Nrow = x_val.shape[0]\n","    Ndiv = 5\n","    n = int(Nrow // Ndiv) + 1\n","    x_val_list = []\n","    for i in range(Ndiv):\n","        tmp = x_val.iloc[i*n : (i+1)*n, :]\n","        x_val_list.append(tmp)\n","    del x_val\n","    gc.collect()\n","\n","    val_pred_list = []\n","    for i, v in enumerate(x_val_list):\n","        print('train pred i=', i)\n","        tmp = model.predict(v)\n","        val_pred_list.append(tmp)\n","    del x_val_list\n","    gc.collect()\n","    val_pred = np.concatenate(val_pred_list)\n","    del val_pred_list\n","    gc.collect()\n","\n","    # Add to out of folds array\n","    # CVを終えれば全部のindexが1回ずつ計算されることになる\n","    oof_predictions[val_ind] = val_pred\n","\n","    # 不要になった時点でモデル削除\n","    del model, y_val\n","    gc.collect()\n"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":47780,"status":"ok","timestamp":1673492529288,"user":{"displayName":"テッツォ","userId":"07789339878611604425"},"user_tz":-540},"id":"x0DTGgkdT2si","colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"4df3e9a6-e982-484b-cda2-a81d245c194c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           session_type                                             labels\n","0       11098528_orders  11830 1732105 588923 884502 876129 571762 1182...\n","1       11098530_orders  409236 1603001 963957 264500 254154 583026 364...\n","2       11098531_orders  1365569 1728212 1271998 396199 452188 1309633 ...\n","3       11098533_orders  1074173 1309900 1165015 765030 935297 508665 8...\n","4       11098534_orders  223062 1449202 908024 1607945 1342293 530377 1...\n","...                 ...                                                ...\n","130756  12899071_orders  153070 1521668 1795459 1300350 1465063 320803 ...\n","130757  12899159_orders  1512596 1131172 1383649 203204 273694 1779500 ...\n","130758  12899329_orders  1333457 356732 1376476 1470364 977011 1667554 ...\n","130759  12899373_orders  1766353 487949 461938 995962 1123180 1662986 1...\n","130760  12899525_orders  996393 1599360 1488793 127479 1734890 1123744 ...\n","\n","[130761 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-17147fcf-ed6e-42f4-8162-f9a5ba821638\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>session_type</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>11098528_orders</td>\n","      <td>11830 1732105 588923 884502 876129 571762 1182...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>11098530_orders</td>\n","      <td>409236 1603001 963957 264500 254154 583026 364...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>11098531_orders</td>\n","      <td>1365569 1728212 1271998 396199 452188 1309633 ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>11098533_orders</td>\n","      <td>1074173 1309900 1165015 765030 935297 508665 8...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11098534_orders</td>\n","      <td>223062 1449202 908024 1607945 1342293 530377 1...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>130756</th>\n","      <td>12899071_orders</td>\n","      <td>153070 1521668 1795459 1300350 1465063 320803 ...</td>\n","    </tr>\n","    <tr>\n","      <th>130757</th>\n","      <td>12899159_orders</td>\n","      <td>1512596 1131172 1383649 203204 273694 1779500 ...</td>\n","    </tr>\n","    <tr>\n","      <th>130758</th>\n","      <td>12899329_orders</td>\n","      <td>1333457 356732 1376476 1470364 977011 1667554 ...</td>\n","    </tr>\n","    <tr>\n","      <th>130759</th>\n","      <td>12899373_orders</td>\n","      <td>1766353 487949 461938 995962 1123180 1662986 1...</td>\n","    </tr>\n","    <tr>\n","      <th>130760</th>\n","      <td>12899525_orders</td>\n","      <td>996393 1599360 1488793 127479 1734890 1123744 ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>130761 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17147fcf-ed6e-42f4-8162-f9a5ba821638')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-17147fcf-ed6e-42f4-8162-f9a5ba821638 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-17147fcf-ed6e-42f4-8162-f9a5ba821638');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":25}],"source":["df = pd.DataFrame(oof_predictions, columns=[\"score\"])\n","df.to_csv(f'{base_path}/otto/oof_lgbm_{TYPE_MODE}.csv', index = False)\n","\n","pred_df = pd.concat([train[['session', 'aid']], df], axis=1)\n","pred_df['session_type'] = pred_df['session'].apply(lambda x: str(x) + f'_{TYPE_MODE}')\n","pred_df = pred_df.sort_values(['session_type','score'],ascending=[True, False]).reset_index(drop=True)\n","\n","pred_df['n'] = pred_df.groupby('session_type').cumcount()\n","pred_df = pred_df.loc[pred_df.n<20].drop(['n','score','session'],axis=1)\n","pred_df['aid'] = pred_df['aid'].astype('int32')\n","pred_df = pred_df.groupby('session_type')['aid'].apply(list).reset_index()\n","pred_df['labels'] = pred_df['aid'].map(lambda x: ''.join(str(x)[1:-1].split(',')))\n","pred_df = pred_df.drop(['aid'],axis=1)\n","pred_df"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":8237,"status":"ok","timestamp":1673492537519,"user":{"displayName":"テッツォ","userId":"07789339878611604425"},"user_tz":-540},"id":"6Jd5N7_5V44c","colab":{"base_uri":"https://localhost:8080/"},"outputId":"83bd6785-281b-4ac5-c744-c2f4752a115d"},"outputs":[{"output_type":"stream","name":"stdout","text":["orders recall = 0.657772188584214\n"]}],"source":["sub = pred_df.loc[pred_df.session_type.str.contains(TYPE_MODE)].copy()\n","sub['session'] = sub.session_type.apply(lambda x: int(x.split('_')[0]))\n","sub.labels = sub.labels.apply(lambda x: [int(i) for i in x.split(' ')[:20]])\n","\n","test_labels = pd.read_parquet(f'{base_path}/input/otto/otto-validation/test_labels.parquet')\n","test_labels = test_labels.loc[test_labels['type']==TYPE_MODE]\n","test_labels = test_labels.merge(sub, how='left', on=['session'])\n","test_labels['labels'] = test_labels['labels'].fillna('[]')\n","test_labels['hits'] = test_labels.apply(lambda df: len(set(df.ground_truth).intersection(set(df.labels))), axis=1)\n","test_labels['gt_count'] = test_labels.ground_truth.str.len().clip(0,20)\n","recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n","print(f'{TYPE_MODE} recall =',recall)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZiU5CW6NeKKS"},"outputs":[],"source":["# click total: 1,755,534\n","# 0.52なら912,877の正解が必要"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LskmzPtiPuzJ"},"outputs":[],"source":["# clicks recall = 0.5271239406357268 おためしtop20, , PB = 0.579\n","\n","# baseline top20のitem2itemを使ってgenerateしたもの, trainsform, duplicate削減、negativeのみremove\n","# clicks recall = 0.5279590141803007 num=100 きた！\n","# 既存データ + 50までbackfill, 20位まで num=100 clicks recall = 0.5289963053976738 きた！\n","#                                               orders recall = 0.6531281219777659\n","# 既存データ + 50までbackfill, 30位まで num=100 orders recall = 0.6533100544839979\n","# 既存データ + 50までbackfill, 50位まで num=100 orders recall = 0.6536483851096223\n","# 既存データ + 50までbackfill, 50位まで num=1000(137) orders recall = 0.6536451933112674\n","\n","# under samplingなしだと上位50で2.1%がpositive\n","# 既存データ + 50までbackfill under sampling pos:neg = 1:2 33% pos, orders recall = 0.6190460991436405\n","#                                            pos:neg = 1:9 10% pos, orders recall = 0.6536036999326531\n","#                                            pos:neg = 1:19 5% pos, orders recall = 0.6536388097145575 ちょい下がるけどそんなに問題なさそう\n","#                                            pos:neg = 1:39 2.5% pos,orders recall= 0.6536930702865916 これくらいの比率で固定しよう, PB = 0.580\n","#                                                                    carts recall = 0.41731398378440265\n","#                                                                    clicks recall = 0.5295727681719636\n","# feature増版、click i2i, top10,20 pos:neg = 1:39 2.5%, num=100 orders recall = 0.6538813863895334\n","#                                                      num=1000 orders recall = 0.654031400912216 , PB = 0.581\n","#                                                      num=1000 carts recall = 0.41827325050912256 \n","#                                                      num=1000 clicks recall = 0.5309427217017728\n","# aid feature追加 2weeks, 4weeks                                orders recall = 0.6575391873043028 ほぼ変わらんのでこっち\n","# 2,3,4 weeks                                                   orders recall = 0.6575551462960776\n","# 2,4 under sampling のsplitだけ変えた                          orders recall = 0.6576381330533062, PB = 0.585\n","#                                                               carts recall = 0.4219628713472407\n","#                                                               clicks_recall = 0.5343416874865425\n","# binary_logloss -> auc, orders recall = 0.6573189532178115 -> binary_loglossのままで良さそう\n","# lr 0.1 -> 0.05, orders recall = 0.6577275034072447 ちょびっとだけ上がった\n","# optuna again (lr=0.05, num=200, order) orders recall = 0.6578519835430877\n","# (other target leak 0.6839768530783299)\n","\n","# kfold古\n","# session feature bug fix orders recall = 0.6576892018269854 logloss下がったのにrecall下がった。。, num=402 valid_1's binary_logloss: 0.0378125\n","# 古いsession素性残し num=335, valid_1's binary_logloss: 0.0378245\n","\n","# kfold sessionごとに変更してsessionのleak修正, 元々のsession素性, orders recall = 0.6577498459957294 [248] valid_1's binary_logloss: 0.0388062\n","# session bug fix orders recall = 0.6579477374937361 [332] valid_1's binary_logloss: 0.0384341 -> binary_loglossがそろそろ信用できない。。\n","# session bug fix + 古い素性残 orders recall = 0.6577562295924393 [272] valid_1's binary_logloss: 0.0384143\n","\n","# recallをmetricsに変更 (otto_lgb_train_rank.ipynb)\n","# session bug fix,orders recall = 0.6577945311726986 [283] valid_1's ndcg@20: 0.843099\tvalid_1's ndcg@50: 0.85066, 時間かかるけどそんなに変わらん\n","# session bug fix,orders recall = 0.657772188584214 map [205] valid_1's map@20: 0.790326\tvalid_1's map@50: 0.792477\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NS3YOf-UgmrY"},"outputs":[],"source":[]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}