{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23974,
     "status": "ok",
     "timestamp": 1673492645207,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "8QrdrLFrx86e",
    "outputId": "4ad1b250-6af1-4baf-c86d-b8a2ba9621df"
   },
   "outputs": [],
   "source": [
    "# True: Google Colab Notebook\n",
    "# False: My local PC\n",
    "colab = False\n",
    "if colab: \n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !ls /content/drive/MyDrive/output/otto/\n",
    "    base_path = '/content/drive/MyDrive'\n",
    "    !pip3 install optuna\n",
    "else:\n",
    "    base_path = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rApCp4mVyLAk"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1336,
     "status": "ok",
     "timestamp": 1673492646537,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "S8Rxu2iww5-9"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 14639,
     "status": "ok",
     "timestamp": 1673495944401,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "oujqBvdabvAs"
   },
   "outputs": [],
   "source": [
    "#train = pd.read_parquet('/content/drive/MyDrive/output/otto/train.parquet')\n",
    "#train = pd.read_parquet('/content/drive/MyDrive/output/otto/train_20.parquet')\n",
    "#train = pd.read_parquet('/content/drive/MyDrive/output/otto/train_50.parquet')\n",
    "train = pd.read_parquet(f'{base_path}/output/otto/train_50_tmp.parquet')\n",
    "\n",
    "#train = pd.read_parquet('/content/drive/MyDrive/output/otto/train_20_old.parquet')\n",
    "\n",
    "#train20 = pd.read_parquet('/content/drive/MyDrive/output/otto/train_20.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1673495944401,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "nE1xweGKyW0a"
   },
   "outputs": [],
   "source": [
    "DEBUG_MODE = False\n",
    "#DEBUG_MODE = True\n",
    "\n",
    "OPTUNA_FLAG = False\n",
    "#OPTUNA_FLAG = True\n",
    "\n",
    "if DEBUG_MODE:\n",
    "    train = train.head(100000)\n",
    "IGNORE_COL = ['session','aid']\n",
    "\n",
    "TYPE_MODE = 'clicks'\n",
    "#TYPE_MODE = 'carts'\n",
    "#TYPE_MODE = 'orders'\n",
    "IGNORE_COL += ['y_clicks', 'y_carts', 'y_orders']\n",
    "\n",
    "\n",
    "if TYPE_MODE == 'clicks':\n",
    "    target = 'y_clicks'\n",
    "    # under sampling 1.3 -> 2.5%\n",
    "    pos_neg_ratio = 1/39\n",
    "elif TYPE_MODE == 'carts':\n",
    "    target = 'y_carts'\n",
    "    # under sampling 1.6 -> 2.5%\n",
    "    pos_neg_ratio = 1/39\n",
    "elif TYPE_MODE == 'orders':\n",
    "    target = 'y_orders'\n",
    "    # under sampling 2.1 -> 2.5%\n",
    "    pos_neg_ratio = 1/39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1673495944401,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "ZHnc3hihwSHY"
   },
   "outputs": [],
   "source": [
    "def reduce_memory(df):\n",
    "    df['session'] = df['session'].astype('int32')\n",
    "    df['aid'] = df['aid'].astype('int32')\n",
    "    df['score_click'] = df['score_click'].astype('float32')\n",
    "    df['score_cart'] = df['score_cart'].astype('float32')\n",
    "    df['score_buy'] = df['score_buy'].astype('float32')\n",
    "    df['score_click_only'] = df['score_click_only'].astype('float32')\n",
    "    df['score_cart_only'] = df['score_cart_only'].astype('float32')\n",
    "    df['score_buy_only'] = df['score_buy_only'].astype('float32')\n",
    "    df['session_action_count'] = df['session_action_count'].astype('int16')\n",
    "    df['session_click_count'] = df['session_click_count'].astype('int16')\n",
    "    df['session_cart_count'] = df['session_cart_count'].astype('int16')\n",
    "    df['session_order_count'] = df['session_order_count'].astype('int16')\n",
    "    df['session_type_mean'] = df['session_type_mean'].astype('float32')\n",
    "    \n",
    "    click_topn_list = [10, 20]\n",
    "    for i in click_topn_list:\n",
    "        df[f'n_clicks_{i}'] = df[f'n_clicks_{i}'].astype('int8')\n",
    "\n",
    "    df['n_carts'] = df['n_carts'].astype('int8')\n",
    "    df['n_buys'] = df['n_buys'].astype('int8')\n",
    "    df['clicks_count'] = df['clicks_count'].astype('int32')\n",
    "    df['carts_count'] = df['carts_count'].astype('int16')\n",
    "    df['orders_count'] = df['orders_count'].astype('int16')\n",
    "    return df\n",
    "\n",
    "# topn件だけを使う\n",
    "def use_top_n(n, df):\n",
    "    df = df.query(f'score_click >= -1 or score_cart >= -1 or score_buy >= -1 or (-1 < n_clicks_20 and n_clicks_20<{n}) or (-1 < n_carts and n_carts<{n}) or (-1 < n_buys and n_buys<{n})')\n",
    "    return df\n",
    "\n",
    "# 負例しかないものは学習に使えないので削る（学習のみ）\n",
    "def remove_negative_session(df):\n",
    "    true_df = df.groupby('session')[target].agg('sum') > 0\n",
    "    session = pd.DataFrame(true_df[true_df]).reset_index()['session']\n",
    "    df = df.merge(session, how = 'inner', on = 'session')\n",
    "    return df\n",
    "\n",
    "# 負例が多すぎる場合にunder samplingする\n",
    "# ratio = pos/neg\n",
    "def negative_sampling(df_x, df_y, ratio):\n",
    "    print('before mean:', df_y.mean())\n",
    "\n",
    "    Nrow = df_x.shape[0]\n",
    "    Ndiv = 5\n",
    "    n = int(Nrow // Ndiv) + 1\n",
    "\n",
    "    df_x_list = [df_x.iloc[i*n : (i+1)*n, :] for i in range(Ndiv)]\n",
    "    df_y_list = [df_y.iloc[i*n : (i+1)*n] for i in range(Ndiv)]\n",
    "    del df_x, df_y\n",
    "    gc.collect()\n",
    "\n",
    "    for i in range(Ndiv):\n",
    "        print('under sampling.......',i + 1 , '/', Ndiv)\n",
    "        tmpx, tmpy = RandomUnderSampler(sampling_strategy=ratio).fit_resample(df_x_list[i], df_y_list[i])\n",
    "        df_x_list[i] = tmpx\n",
    "        df_y_list[i] = tmpy\n",
    "        del tmpx, tmpy\n",
    "        gc.collect()\n",
    "    print('under sampling end')\n",
    "    after_x = pd.concat(df_x_list)\n",
    "    del df_x_list\n",
    "    gc.collect()\n",
    "    print('post proccess1')\n",
    "    after_y = pd.concat(df_y_list)\n",
    "    del df_y_list\n",
    "    gc.collect()\n",
    "\n",
    "    print('after mean:', after_y.mean())\n",
    "    return after_x, after_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1673495944402,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "KvbDeqvHbMn8"
   },
   "outputs": [],
   "source": [
    "def join_session_features(df):\n",
    "    session_df = pd.read_parquet(f'{base_path}/output/otto/valid_session_features.parquet')\n",
    "    session_df['session'] = session_df['session'].astype('int32')\n",
    "    session_df[f'session_action_count'] = session_df[f'session_action_count'].astype('int16')\n",
    "    session_df[f'session_click_count'] = session_df[f'session_click_count'].astype('int16')\n",
    "    session_df[f'session_cart_count'] = session_df[f'session_cart_count'].astype('int16')\n",
    "    session_df[f'session_order_count'] = session_df[f'session_order_count'].astype('int16')\n",
    "    session_df[f'session_type_mean'] = session_df[f'session_type_mean'].astype('float32')\n",
    "    session_df[f'session_click_rate'] = session_df[f'session_click_rate'].astype('float32')\n",
    "    session_df[f'session_cart_rate'] = session_df[f'session_cart_rate'].astype('float32')\n",
    "    session_df[f'session_order_rate'] = session_df[f'session_order_rate'].astype('float32')\n",
    "\n",
    "    remove_col = ['session_action_count', 'session_click_count', 'session_cart_count', 'session_order_count', 'session_type_mean']\n",
    "    df = df.drop(remove_col , axis=1)\n",
    "    df = df.merge(session_df, 'left', 'session')\n",
    "    del session_df\n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1673495944402,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "TT-tm_hPbPpA"
   },
   "outputs": [],
   "source": [
    "def join_aid_features(df):\n",
    "    aid_df = pd.read_parquet(f'{base_path}/output/otto/valid_aid_features.parquet')\n",
    "    #week_list = ['4weeks', '3weeks', '2weeks', '1week']\n",
    "    week_list = ['4weeks', '2weeks', '1week']\n",
    "    aid_df['aid'] = aid_df['aid'].astype('int32')\n",
    "    for i in week_list:\n",
    "        aid_df[f'clicks_count_{i}'] = aid_df[f'clicks_count_{i}'].astype('int32')\n",
    "        aid_df[f'carts_count_{i}'] = aid_df[f'carts_count_{i}'].astype('int16')\n",
    "        aid_df[f'orders_count_{i}'] = aid_df[f'orders_count_{i}'].astype('int16')\n",
    "        aid_df[f'clicks_rank_{i}'] = aid_df[f'clicks_rank_{i}'].astype('int32')\n",
    "        aid_df[f'carts_rank_{i}'] = aid_df[f'carts_rank_{i}'].astype('int32')\n",
    "        aid_df[f'orders_rank_{i}'] = aid_df[f'orders_rank_{i}'].astype('int32')\n",
    "        for j in ['clicks', 'carts', 'orders']:\n",
    "            #for k in [2,3,4]:\n",
    "            for k in [2,4]:\n",
    "                aid_df[f'aid_{j}_count_rate_1_{k}'] = aid_df[f'aid_{j}_count_rate_1_{k}'].astype('float32')\n",
    "\n",
    "    remove_col = ['clicks_rank', 'carts_rank', 'orders_rank', 'clicks_count', 'carts_count', 'orders_count']\n",
    "    #remove_col = ['clicks_rank_1week', 'carts_rank_1week', 'orders_rank_1week', 'clicks_count_1week', 'carts_count_1week', 'orders_count_1week']\n",
    "    #df.drop(remove_col , axis=1)\n",
    "    df = df.merge(aid_df, 'left', 'aid')\n",
    "    del aid_df\n",
    "    gc.collect()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 17972,
     "status": "ok",
     "timestamp": 1673495962370,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "fr7uXIlVxvEJ"
   },
   "outputs": [],
   "source": [
    "train = reduce_memory(train)\n",
    "train = use_top_n(50, train)\n",
    "train = remove_negative_session(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1673495962371,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "yyec9GHZypQ5",
    "outputId": "2703dbd5-6b38-474e-efc3-c23126db307d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1012735"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[target].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1673495962371,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "RGToJvwN2dxO",
    "outputId": "d50cb75c-25cd-4dec-ed0a-7a3dad8ace98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013401377389554573"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 9070,
     "status": "ok",
     "timestamp": 1673495971437,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "bmasKtdlgXRF"
   },
   "outputs": [],
   "source": [
    "train = join_session_features(train)\n",
    "train = join_aid_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1673495971438,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "QkjpGWm5LUwq"
   },
   "outputs": [],
   "source": [
    "# WIP\n",
    "TRAIN_SECOND = False\n",
    "if TRAIN_SECOND:\n",
    "    # target以外の予測値の読み込み\n",
    "    train = pd.read_csv(f'{base_path}/otto/oof_lgbm_{TYPE_MODE}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1673495971438,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "eY1bGfqgM-Oi",
    "outputId": "ff437791-dd87-4cc1-bea0-1b4da7999f43"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session                        int32\n",
       "aid                            int32\n",
       "score_click                  float32\n",
       "score_cart                   float32\n",
       "score_buy                    float32\n",
       "score_click_only             float32\n",
       "score_cart_only              float32\n",
       "score_buy_only               float32\n",
       "n_clicks_10                     int8\n",
       "n_clicks_20                     int8\n",
       "n_carts                         int8\n",
       "n_buys                          int8\n",
       "clicks_rank                    int32\n",
       "carts_rank                     int32\n",
       "orders_rank                    int32\n",
       "clicks_count                   int32\n",
       "carts_count                    int16\n",
       "orders_count                   int16\n",
       "y_clicks                        bool\n",
       "y_carts                         bool\n",
       "y_orders                        bool\n",
       "session_action_count           int16\n",
       "session_click_count            int16\n",
       "session_cart_count             int16\n",
       "session_order_count            int16\n",
       "session_type_mean            float32\n",
       "session_click_rate           float32\n",
       "session_cart_rate            float32\n",
       "session_order_rate           float32\n",
       "clicks_count_4weeks            int32\n",
       "carts_count_4weeks             int16\n",
       "orders_count_4weeks            int16\n",
       "clicks_rank_4weeks             int32\n",
       "carts_rank_4weeks              int32\n",
       "orders_rank_4weeks             int32\n",
       "clicks_count_2weeks            int32\n",
       "carts_count_2weeks             int16\n",
       "orders_count_2weeks            int16\n",
       "clicks_rank_2weeks             int32\n",
       "carts_rank_2weeks              int32\n",
       "orders_rank_2weeks             int32\n",
       "clicks_count_1week             int32\n",
       "carts_count_1week              int16\n",
       "orders_count_1week             int16\n",
       "clicks_rank_1week              int32\n",
       "carts_rank_1week               int32\n",
       "orders_rank_1week              int32\n",
       "aid_clicks_count_rate_1_2    float32\n",
       "aid_clicks_count_rate_1_4    float32\n",
       "aid_carts_count_rate_1_2     float32\n",
       "aid_carts_count_rate_1_4     float32\n",
       "aid_orders_count_rate_1_2    float32\n",
       "aid_orders_count_rate_1_4    float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOW-eeZAyZT8"
   },
   "source": [
    "# Training & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1673495971438,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "we5IplsR8tQ2"
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import itertools\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# optuna\n",
    "if OPTUNA_FLAG:\n",
    "    import optuna.integration.lightgbm as lgb\n",
    "else:\n",
    "    import lightgbm as lgb\n",
    "\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1673495971438,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "yjzMNkv_MGj9"
   },
   "outputs": [],
   "source": [
    "# old 0.0382316\n",
    "# new 0.03822381002014941.\n",
    "# new num=1000\n",
    "if OPTUNA_FLAG:\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',  # Noneにした方がよさそう？\n",
    "        'boosting': 'gbdt',\n",
    "        'seed': 42,        \n",
    "        'n_jobs': -1,\n",
    "        'learning_rate': 0.05\n",
    "        }\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "    for fold, (trn_ind, val_ind) in enumerate(kfold.split(train)):\n",
    "        print(' ')\n",
    "        print('-'*50)\n",
    "        print(f'Training fold {fold}...')\n",
    "\n",
    "        y_train, y_val = train[target].iloc[trn_ind], train[target].iloc[val_ind]\n",
    "        train_tmp = train.drop(IGNORE_COL , axis=1)\n",
    "        x_train, x_val = train_tmp.iloc[trn_ind], train_tmp.iloc[val_ind]\n",
    "        del train_tmp\n",
    "        gc.collect()\n",
    "\n",
    "        # under sampling\n",
    "        x_train, y_train = negative_sampling(x_train, y_train, pos_neg_ratio)\n",
    "\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        lgb_valid = lgb.Dataset(x_val, y_val)\n",
    "        del x_train, y_train\n",
    "        gc.collect()\n",
    "\n",
    "        #lgb_valid = lgb.Dataset(x_val, y_val)\n",
    "        model = lgb.train(\n",
    "            params = params,\n",
    "            train_set = lgb_train,\n",
    "            #num_boost_round = 10500,\n",
    "            num_boost_round = 200,\n",
    "            valid_sets = [lgb_train, lgb_valid],\n",
    "            early_stopping_rounds = 20,\n",
    "            verbose_eval = 10,\n",
    "            )\n",
    "        del lgb_train, lgb_valid\n",
    "        gc.collect()\n",
    "        break\n",
    "    model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1673495971439,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "aTlbPCG4PKNS"
   },
   "outputs": [],
   "source": [
    "if OPTUNA_FLAG:\n",
    "    print(\"Optuna results: \",model.params)\n",
    "\n",
    "params = {'objective': 'binary',\n",
    "          'metric': 'binary_logloss',\n",
    "          'boosting': 'gbdt',\n",
    "          'seed': 42,\n",
    "          'n_jobs': -1,\n",
    "          'learning_rate': 0.05,\n",
    "          'feature_pre_filter': False,\n",
    "          'lambda_l1': 7.777864227173249,\n",
    "          'lambda_l2': 0.000181104589355317,\n",
    "          'num_leaves': 202,\n",
    "          'feature_fraction': 0.8999999999999999,\n",
    "          'bagging_fraction': 1.0,\n",
    "          'bagging_freq': 0,\n",
    "          'min_child_samples': 25\n",
    "          }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1809000,
     "status": "ok",
     "timestamp": 1673497780418,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "E6kHtxYa93k_",
    "outputId": "ff8d8dc4-34c6-4d9e-87e1-fd7fd54cd94f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "--------------------------------------------------\n",
      "Training fold 0...\n",
      "before mean: 0.013400967040807624\n",
      "under sampling....... 1 / 5\n",
      "under sampling....... 2 / 5\n",
      "under sampling....... 3 / 5\n",
      "under sampling....... 4 / 5\n",
      "under sampling....... 5 / 5\n",
      "under sampling end\n",
      "post proccess1\n",
      "after mean: 0.025\n",
      "[LightGBM] [Info] Number of positive: 810188, number of negative: 31597332\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.757861 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9818\n",
      "[LightGBM] [Info] Number of data points in the train set: 32407520, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.025000 -> initscore=-3.663562\n",
      "[LightGBM] [Info] Start training from score -3.663562\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.0806423\tvalid_1's binary_logloss: 0.0538225\n",
      "[20]\ttraining's binary_logloss: 0.0732785\tvalid_1's binary_logloss: 0.049239\n",
      "[30]\ttraining's binary_logloss: 0.0699452\tvalid_1's binary_logloss: 0.0471316\n",
      "[40]\ttraining's binary_logloss: 0.0682533\tvalid_1's binary_logloss: 0.0460637\n",
      "[50]\ttraining's binary_logloss: 0.0673436\tvalid_1's binary_logloss: 0.0454948\n",
      "[60]\ttraining's binary_logloss: 0.0668304\tvalid_1's binary_logloss: 0.0451778\n",
      "[70]\ttraining's binary_logloss: 0.0665312\tvalid_1's binary_logloss: 0.0449954\n",
      "[80]\ttraining's binary_logloss: 0.0663482\tvalid_1's binary_logloss: 0.0448873\n",
      "[90]\ttraining's binary_logloss: 0.0662298\tvalid_1's binary_logloss: 0.0448215\n",
      "[100]\ttraining's binary_logloss: 0.0661474\tvalid_1's binary_logloss: 0.0447781\n",
      "[110]\ttraining's binary_logloss: 0.0660847\tvalid_1's binary_logloss: 0.0447478\n",
      "[120]\ttraining's binary_logloss: 0.0660331\tvalid_1's binary_logloss: 0.0447255\n",
      "[130]\ttraining's binary_logloss: 0.0659879\tvalid_1's binary_logloss: 0.0447076\n",
      "[140]\ttraining's binary_logloss: 0.0659503\tvalid_1's binary_logloss: 0.0446939\n",
      "[150]\ttraining's binary_logloss: 0.0659132\tvalid_1's binary_logloss: 0.0446816\n",
      "[160]\ttraining's binary_logloss: 0.0658791\tvalid_1's binary_logloss: 0.0446719\n",
      "[170]\ttraining's binary_logloss: 0.0658473\tvalid_1's binary_logloss: 0.044663\n",
      "[180]\ttraining's binary_logloss: 0.0658187\tvalid_1's binary_logloss: 0.0446552\n",
      "[190]\ttraining's binary_logloss: 0.0657909\tvalid_1's binary_logloss: 0.0446496\n",
      "[200]\ttraining's binary_logloss: 0.0657625\tvalid_1's binary_logloss: 0.0446427\n",
      "[210]\ttraining's binary_logloss: 0.0657346\tvalid_1's binary_logloss: 0.0446371\n",
      "[220]\ttraining's binary_logloss: 0.0657087\tvalid_1's binary_logloss: 0.044633\n",
      "[230]\ttraining's binary_logloss: 0.0656838\tvalid_1's binary_logloss: 0.0446284\n",
      "[240]\ttraining's binary_logloss: 0.0656592\tvalid_1's binary_logloss: 0.0446244\n",
      "[250]\ttraining's binary_logloss: 0.0656344\tvalid_1's binary_logloss: 0.0446199\n",
      "[260]\ttraining's binary_logloss: 0.0656118\tvalid_1's binary_logloss: 0.0446152\n",
      "[270]\ttraining's binary_logloss: 0.0655889\tvalid_1's binary_logloss: 0.044612\n",
      "[280]\ttraining's binary_logloss: 0.0655673\tvalid_1's binary_logloss: 0.0446088\n",
      "[290]\ttraining's binary_logloss: 0.0655434\tvalid_1's binary_logloss: 0.0446047\n",
      "[300]\ttraining's binary_logloss: 0.0655216\tvalid_1's binary_logloss: 0.0446025\n",
      "[310]\ttraining's binary_logloss: 0.0654991\tvalid_1's binary_logloss: 0.0446005\n",
      "[320]\ttraining's binary_logloss: 0.0654783\tvalid_1's binary_logloss: 0.0445981\n",
      "[330]\ttraining's binary_logloss: 0.0654572\tvalid_1's binary_logloss: 0.0445947\n",
      "[340]\ttraining's binary_logloss: 0.065437\tvalid_1's binary_logloss: 0.0445916\n",
      "[350]\ttraining's binary_logloss: 0.0654144\tvalid_1's binary_logloss: 0.0445887\n",
      "[360]\ttraining's binary_logloss: 0.0653927\tvalid_1's binary_logloss: 0.0445859\n",
      "[370]\ttraining's binary_logloss: 0.0653711\tvalid_1's binary_logloss: 0.0445833\n",
      "[380]\ttraining's binary_logloss: 0.0653494\tvalid_1's binary_logloss: 0.0445797\n",
      "[390]\ttraining's binary_logloss: 0.0653277\tvalid_1's binary_logloss: 0.0445764\n",
      "[400]\ttraining's binary_logloss: 0.0653072\tvalid_1's binary_logloss: 0.0445743\n",
      "[410]\ttraining's binary_logloss: 0.0652872\tvalid_1's binary_logloss: 0.0445718\n",
      "[420]\ttraining's binary_logloss: 0.0652661\tvalid_1's binary_logloss: 0.0445697\n",
      "[430]\ttraining's binary_logloss: 0.0652459\tvalid_1's binary_logloss: 0.0445672\n",
      "[440]\ttraining's binary_logloss: 0.0652253\tvalid_1's binary_logloss: 0.0445644\n",
      "[450]\ttraining's binary_logloss: 0.0652077\tvalid_1's binary_logloss: 0.044563\n",
      "[460]\ttraining's binary_logloss: 0.0651881\tvalid_1's binary_logloss: 0.0445612\n",
      "[470]\ttraining's binary_logloss: 0.0651711\tvalid_1's binary_logloss: 0.0445598\n",
      "[480]\ttraining's binary_logloss: 0.0651535\tvalid_1's binary_logloss: 0.0445583\n",
      "[490]\ttraining's binary_logloss: 0.0651365\tvalid_1's binary_logloss: 0.044557\n",
      "[500]\ttraining's binary_logloss: 0.0651194\tvalid_1's binary_logloss: 0.044556\n",
      "[510]\ttraining's binary_logloss: 0.0650996\tvalid_1's binary_logloss: 0.0445538\n",
      "[520]\ttraining's binary_logloss: 0.0650813\tvalid_1's binary_logloss: 0.0445526\n",
      "[530]\ttraining's binary_logloss: 0.0650657\tvalid_1's binary_logloss: 0.0445516\n",
      "[540]\ttraining's binary_logloss: 0.0650454\tvalid_1's binary_logloss: 0.0445494\n",
      "[550]\ttraining's binary_logloss: 0.0650281\tvalid_1's binary_logloss: 0.0445479\n",
      "[560]\ttraining's binary_logloss: 0.0650108\tvalid_1's binary_logloss: 0.0445468\n",
      "[570]\ttraining's binary_logloss: 0.0649921\tvalid_1's binary_logloss: 0.0445462\n",
      "[580]\ttraining's binary_logloss: 0.0649743\tvalid_1's binary_logloss: 0.0445447\n",
      "[590]\ttraining's binary_logloss: 0.0649565\tvalid_1's binary_logloss: 0.0445435\n",
      "[600]\ttraining's binary_logloss: 0.0649375\tvalid_1's binary_logloss: 0.0445417\n",
      "[610]\ttraining's binary_logloss: 0.0649202\tvalid_1's binary_logloss: 0.0445404\n",
      "[620]\ttraining's binary_logloss: 0.0649023\tvalid_1's binary_logloss: 0.0445394\n",
      "[630]\ttraining's binary_logloss: 0.0648838\tvalid_1's binary_logloss: 0.0445377\n",
      "[640]\ttraining's binary_logloss: 0.0648661\tvalid_1's binary_logloss: 0.0445366\n",
      "[650]\ttraining's binary_logloss: 0.064849\tvalid_1's binary_logloss: 0.0445356\n",
      "[660]\ttraining's binary_logloss: 0.0648333\tvalid_1's binary_logloss: 0.0445352\n",
      "[670]\ttraining's binary_logloss: 0.0648164\tvalid_1's binary_logloss: 0.0445341\n",
      "[680]\ttraining's binary_logloss: 0.0648012\tvalid_1's binary_logloss: 0.044534\n",
      "[690]\ttraining's binary_logloss: 0.0647872\tvalid_1's binary_logloss: 0.0445334\n",
      "[700]\ttraining's binary_logloss: 0.0647699\tvalid_1's binary_logloss: 0.0445326\n",
      "[710]\ttraining's binary_logloss: 0.0647533\tvalid_1's binary_logloss: 0.0445317\n",
      "[720]\ttraining's binary_logloss: 0.0647345\tvalid_1's binary_logloss: 0.0445308\n",
      "[730]\ttraining's binary_logloss: 0.064718\tvalid_1's binary_logloss: 0.0445294\n",
      "[740]\ttraining's binary_logloss: 0.0647014\tvalid_1's binary_logloss: 0.0445286\n",
      "[750]\ttraining's binary_logloss: 0.0646878\tvalid_1's binary_logloss: 0.044528\n",
      "[760]\ttraining's binary_logloss: 0.0646728\tvalid_1's binary_logloss: 0.0445268\n",
      "[770]\ttraining's binary_logloss: 0.0646563\tvalid_1's binary_logloss: 0.044526\n",
      "[780]\ttraining's binary_logloss: 0.0646414\tvalid_1's binary_logloss: 0.0445257\n",
      "[790]\ttraining's binary_logloss: 0.0646256\tvalid_1's binary_logloss: 0.0445249\n",
      "[800]\ttraining's binary_logloss: 0.0646089\tvalid_1's binary_logloss: 0.0445243\n",
      "[810]\ttraining's binary_logloss: 0.0645936\tvalid_1's binary_logloss: 0.0445239\n",
      "[820]\ttraining's binary_logloss: 0.0645777\tvalid_1's binary_logloss: 0.0445232\n",
      "[830]\ttraining's binary_logloss: 0.0645618\tvalid_1's binary_logloss: 0.0445221\n",
      "[840]\ttraining's binary_logloss: 0.0645475\tvalid_1's binary_logloss: 0.0445213\n",
      "[850]\ttraining's binary_logloss: 0.064534\tvalid_1's binary_logloss: 0.0445208\n",
      "[860]\ttraining's binary_logloss: 0.064519\tvalid_1's binary_logloss: 0.0445203\n",
      "[870]\ttraining's binary_logloss: 0.0645041\tvalid_1's binary_logloss: 0.0445194\n",
      "[880]\ttraining's binary_logloss: 0.0644887\tvalid_1's binary_logloss: 0.0445186\n",
      "[890]\ttraining's binary_logloss: 0.0644727\tvalid_1's binary_logloss: 0.0445175\n",
      "[900]\ttraining's binary_logloss: 0.0644561\tvalid_1's binary_logloss: 0.0445165\n",
      "[910]\ttraining's binary_logloss: 0.0644397\tvalid_1's binary_logloss: 0.0445154\n",
      "[920]\ttraining's binary_logloss: 0.0644239\tvalid_1's binary_logloss: 0.0445146\n",
      "[930]\ttraining's binary_logloss: 0.0644084\tvalid_1's binary_logloss: 0.0445137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[940]\ttraining's binary_logloss: 0.0643953\tvalid_1's binary_logloss: 0.0445133\n",
      "[950]\ttraining's binary_logloss: 0.0643826\tvalid_1's binary_logloss: 0.044513\n",
      "[960]\ttraining's binary_logloss: 0.0643677\tvalid_1's binary_logloss: 0.044512\n",
      "[970]\ttraining's binary_logloss: 0.0643523\tvalid_1's binary_logloss: 0.044511\n",
      "[980]\ttraining's binary_logloss: 0.0643365\tvalid_1's binary_logloss: 0.0445107\n",
      "[990]\ttraining's binary_logloss: 0.0643206\tvalid_1's binary_logloss: 0.0445098\n",
      "[1000]\ttraining's binary_logloss: 0.0643048\tvalid_1's binary_logloss: 0.0445092\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.0643048\tvalid_1's binary_logloss: 0.0445092\n",
      "train pred i= 0\n",
      "train pred i= 1\n",
      "train pred i= 2\n",
      "train pred i= 3\n",
      "train pred i= 4\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 1...\n",
      "before mean: 0.013401513897263122\n",
      "under sampling....... 1 / 5\n",
      "under sampling....... 2 / 5\n",
      "under sampling....... 3 / 5\n",
      "under sampling....... 4 / 5\n",
      "under sampling....... 5 / 5\n",
      "under sampling end\n",
      "post proccess1\n",
      "after mean: 0.025\n",
      "[LightGBM] [Info] Number of positive: 810188, number of negative: 31597332\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.767555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9813\n",
      "[LightGBM] [Info] Number of data points in the train set: 32407520, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.025000 -> initscore=-3.663562\n",
      "[LightGBM] [Info] Start training from score -3.663562\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.0806255\tvalid_1's binary_logloss: 0.0538297\n",
      "[20]\ttraining's binary_logloss: 0.0732581\tvalid_1's binary_logloss: 0.0492483\n",
      "[30]\ttraining's binary_logloss: 0.0699245\tvalid_1's binary_logloss: 0.0471436\n",
      "[40]\ttraining's binary_logloss: 0.0682361\tvalid_1's binary_logloss: 0.0460798\n",
      "[50]\ttraining's binary_logloss: 0.0673282\tvalid_1's binary_logloss: 0.0455112\n",
      "[60]\ttraining's binary_logloss: 0.0668178\tvalid_1's binary_logloss: 0.0451965\n",
      "[70]\ttraining's binary_logloss: 0.0665182\tvalid_1's binary_logloss: 0.0450148\n",
      "[80]\ttraining's binary_logloss: 0.0663344\tvalid_1's binary_logloss: 0.0449066\n",
      "[90]\ttraining's binary_logloss: 0.0662185\tvalid_1's binary_logloss: 0.0448412\n",
      "[100]\ttraining's binary_logloss: 0.0661365\tvalid_1's binary_logloss: 0.0447976\n",
      "[110]\ttraining's binary_logloss: 0.0660747\tvalid_1's binary_logloss: 0.0447676\n",
      "[120]\ttraining's binary_logloss: 0.0660213\tvalid_1's binary_logloss: 0.0447431\n",
      "[130]\ttraining's binary_logloss: 0.0659766\tvalid_1's binary_logloss: 0.044724\n",
      "[140]\ttraining's binary_logloss: 0.0659386\tvalid_1's binary_logloss: 0.0447095\n",
      "[150]\ttraining's binary_logloss: 0.0659054\tvalid_1's binary_logloss: 0.0446977\n",
      "[160]\ttraining's binary_logloss: 0.0658731\tvalid_1's binary_logloss: 0.0446875\n",
      "[170]\ttraining's binary_logloss: 0.0658429\tvalid_1's binary_logloss: 0.0446785\n",
      "[180]\ttraining's binary_logloss: 0.0658145\tvalid_1's binary_logloss: 0.0446714\n",
      "[190]\ttraining's binary_logloss: 0.065786\tvalid_1's binary_logloss: 0.044665\n",
      "[200]\ttraining's binary_logloss: 0.0657575\tvalid_1's binary_logloss: 0.0446585\n",
      "[210]\ttraining's binary_logloss: 0.0657318\tvalid_1's binary_logloss: 0.0446528\n",
      "[220]\ttraining's binary_logloss: 0.0657072\tvalid_1's binary_logloss: 0.044649\n",
      "[230]\ttraining's binary_logloss: 0.0656815\tvalid_1's binary_logloss: 0.0446447\n",
      "[240]\ttraining's binary_logloss: 0.0656562\tvalid_1's binary_logloss: 0.0446401\n",
      "[250]\ttraining's binary_logloss: 0.065632\tvalid_1's binary_logloss: 0.0446352\n",
      "[260]\ttraining's binary_logloss: 0.0656107\tvalid_1's binary_logloss: 0.0446321\n",
      "[270]\ttraining's binary_logloss: 0.0655887\tvalid_1's binary_logloss: 0.0446293\n",
      "[280]\ttraining's binary_logloss: 0.0655669\tvalid_1's binary_logloss: 0.0446259\n",
      "[290]\ttraining's binary_logloss: 0.0655458\tvalid_1's binary_logloss: 0.0446234\n",
      "[300]\ttraining's binary_logloss: 0.0655248\tvalid_1's binary_logloss: 0.0446209\n",
      "[310]\ttraining's binary_logloss: 0.065504\tvalid_1's binary_logloss: 0.0446181\n",
      "[320]\ttraining's binary_logloss: 0.0654834\tvalid_1's binary_logloss: 0.0446147\n",
      "[330]\ttraining's binary_logloss: 0.0654592\tvalid_1's binary_logloss: 0.0446111\n",
      "[340]\ttraining's binary_logloss: 0.0654405\tvalid_1's binary_logloss: 0.0446088\n",
      "[350]\ttraining's binary_logloss: 0.0654216\tvalid_1's binary_logloss: 0.0446069\n",
      "[360]\ttraining's binary_logloss: 0.0654042\tvalid_1's binary_logloss: 0.0446047\n",
      "[370]\ttraining's binary_logloss: 0.0653859\tvalid_1's binary_logloss: 0.0446026\n",
      "[380]\ttraining's binary_logloss: 0.0653657\tvalid_1's binary_logloss: 0.0446002\n",
      "[390]\ttraining's binary_logloss: 0.0653451\tvalid_1's binary_logloss: 0.0445978\n",
      "[400]\ttraining's binary_logloss: 0.0653263\tvalid_1's binary_logloss: 0.0445957\n",
      "[410]\ttraining's binary_logloss: 0.0653056\tvalid_1's binary_logloss: 0.044594\n",
      "[420]\ttraining's binary_logloss: 0.0652829\tvalid_1's binary_logloss: 0.0445904\n",
      "[430]\ttraining's binary_logloss: 0.0652641\tvalid_1's binary_logloss: 0.0445878\n",
      "[440]\ttraining's binary_logloss: 0.0652444\tvalid_1's binary_logloss: 0.0445854\n",
      "[450]\ttraining's binary_logloss: 0.0652248\tvalid_1's binary_logloss: 0.044584\n",
      "[460]\ttraining's binary_logloss: 0.0652054\tvalid_1's binary_logloss: 0.0445828\n",
      "[470]\ttraining's binary_logloss: 0.0651846\tvalid_1's binary_logloss: 0.0445805\n",
      "[480]\ttraining's binary_logloss: 0.0651634\tvalid_1's binary_logloss: 0.0445786\n",
      "[490]\ttraining's binary_logloss: 0.0651457\tvalid_1's binary_logloss: 0.0445777\n",
      "[500]\ttraining's binary_logloss: 0.0651265\tvalid_1's binary_logloss: 0.0445756\n",
      "[510]\ttraining's binary_logloss: 0.065108\tvalid_1's binary_logloss: 0.0445744\n",
      "[520]\ttraining's binary_logloss: 0.0650909\tvalid_1's binary_logloss: 0.0445735\n",
      "[530]\ttraining's binary_logloss: 0.0650741\tvalid_1's binary_logloss: 0.0445726\n",
      "[540]\ttraining's binary_logloss: 0.065059\tvalid_1's binary_logloss: 0.0445718\n",
      "[550]\ttraining's binary_logloss: 0.0650412\tvalid_1's binary_logloss: 0.0445705\n",
      "[560]\ttraining's binary_logloss: 0.0650228\tvalid_1's binary_logloss: 0.0445692\n",
      "[570]\ttraining's binary_logloss: 0.0650047\tvalid_1's binary_logloss: 0.0445676\n",
      "[580]\ttraining's binary_logloss: 0.0649864\tvalid_1's binary_logloss: 0.0445661\n",
      "[590]\ttraining's binary_logloss: 0.0649692\tvalid_1's binary_logloss: 0.0445652\n",
      "[600]\ttraining's binary_logloss: 0.0649512\tvalid_1's binary_logloss: 0.0445636\n",
      "[610]\ttraining's binary_logloss: 0.0649326\tvalid_1's binary_logloss: 0.0445619\n",
      "[620]\ttraining's binary_logloss: 0.0649163\tvalid_1's binary_logloss: 0.0445607\n",
      "[630]\ttraining's binary_logloss: 0.064899\tvalid_1's binary_logloss: 0.0445589\n",
      "[640]\ttraining's binary_logloss: 0.0648808\tvalid_1's binary_logloss: 0.0445573\n",
      "[650]\ttraining's binary_logloss: 0.0648652\tvalid_1's binary_logloss: 0.0445565\n",
      "[660]\ttraining's binary_logloss: 0.0648465\tvalid_1's binary_logloss: 0.0445548\n",
      "[670]\ttraining's binary_logloss: 0.064832\tvalid_1's binary_logloss: 0.0445545\n",
      "[680]\ttraining's binary_logloss: 0.0648167\tvalid_1's binary_logloss: 0.0445542\n",
      "[690]\ttraining's binary_logloss: 0.0647994\tvalid_1's binary_logloss: 0.0445531\n",
      "[700]\ttraining's binary_logloss: 0.0647821\tvalid_1's binary_logloss: 0.0445521\n",
      "[710]\ttraining's binary_logloss: 0.0647655\tvalid_1's binary_logloss: 0.0445514\n",
      "[720]\ttraining's binary_logloss: 0.0647515\tvalid_1's binary_logloss: 0.0445506\n",
      "[730]\ttraining's binary_logloss: 0.0647341\tvalid_1's binary_logloss: 0.0445494\n",
      "[740]\ttraining's binary_logloss: 0.0647183\tvalid_1's binary_logloss: 0.0445485\n",
      "[750]\ttraining's binary_logloss: 0.0647034\tvalid_1's binary_logloss: 0.044548\n",
      "[760]\ttraining's binary_logloss: 0.064688\tvalid_1's binary_logloss: 0.0445465\n",
      "[770]\ttraining's binary_logloss: 0.0646697\tvalid_1's binary_logloss: 0.0445451\n",
      "[780]\ttraining's binary_logloss: 0.0646514\tvalid_1's binary_logloss: 0.0445442\n",
      "[790]\ttraining's binary_logloss: 0.064634\tvalid_1's binary_logloss: 0.0445436\n",
      "[800]\ttraining's binary_logloss: 0.064617\tvalid_1's binary_logloss: 0.0445419\n",
      "[810]\ttraining's binary_logloss: 0.0646023\tvalid_1's binary_logloss: 0.0445408\n",
      "[820]\ttraining's binary_logloss: 0.0645862\tvalid_1's binary_logloss: 0.0445405\n",
      "[830]\ttraining's binary_logloss: 0.0645706\tvalid_1's binary_logloss: 0.0445402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[840]\ttraining's binary_logloss: 0.0645548\tvalid_1's binary_logloss: 0.0445396\n",
      "[850]\ttraining's binary_logloss: 0.0645401\tvalid_1's binary_logloss: 0.0445385\n",
      "[860]\ttraining's binary_logloss: 0.0645246\tvalid_1's binary_logloss: 0.0445378\n",
      "[870]\ttraining's binary_logloss: 0.0645087\tvalid_1's binary_logloss: 0.0445367\n",
      "[880]\ttraining's binary_logloss: 0.0644925\tvalid_1's binary_logloss: 0.044536\n",
      "[890]\ttraining's binary_logloss: 0.064477\tvalid_1's binary_logloss: 0.044535\n",
      "[900]\ttraining's binary_logloss: 0.0644608\tvalid_1's binary_logloss: 0.0445346\n",
      "[910]\ttraining's binary_logloss: 0.0644448\tvalid_1's binary_logloss: 0.044534\n",
      "[920]\ttraining's binary_logloss: 0.064428\tvalid_1's binary_logloss: 0.044533\n",
      "[930]\ttraining's binary_logloss: 0.0644129\tvalid_1's binary_logloss: 0.0445323\n",
      "[940]\ttraining's binary_logloss: 0.0643968\tvalid_1's binary_logloss: 0.0445317\n",
      "[950]\ttraining's binary_logloss: 0.0643803\tvalid_1's binary_logloss: 0.0445314\n",
      "[960]\ttraining's binary_logloss: 0.0643644\tvalid_1's binary_logloss: 0.0445312\n",
      "[970]\ttraining's binary_logloss: 0.0643487\tvalid_1's binary_logloss: 0.0445307\n",
      "[980]\ttraining's binary_logloss: 0.0643321\tvalid_1's binary_logloss: 0.04453\n",
      "[990]\ttraining's binary_logloss: 0.0643162\tvalid_1's binary_logloss: 0.0445293\n",
      "[1000]\ttraining's binary_logloss: 0.064301\tvalid_1's binary_logloss: 0.0445287\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.064301\tvalid_1's binary_logloss: 0.0445287\n",
      "train pred i= 0\n",
      "train pred i= 1\n",
      "train pred i= 2\n",
      "train pred i= 3\n",
      "train pred i= 4\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 2...\n",
      "before mean: 0.013401475990491593\n",
      "under sampling....... 1 / 5\n",
      "under sampling....... 2 / 5\n",
      "under sampling....... 3 / 5\n",
      "under sampling....... 4 / 5\n",
      "under sampling....... 5 / 5\n",
      "under sampling end\n",
      "post proccess1\n",
      "after mean: 0.025\n",
      "[LightGBM] [Info] Number of positive: 810188, number of negative: 31597332\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.601590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9816\n",
      "[LightGBM] [Info] Number of data points in the train set: 32407520, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.025000 -> initscore=-3.663562\n",
      "[LightGBM] [Info] Start training from score -3.663562\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.0806016\tvalid_1's binary_logloss: 0.0539046\n",
      "[20]\ttraining's binary_logloss: 0.0732341\tvalid_1's binary_logloss: 0.0493325\n",
      "[30]\ttraining's binary_logloss: 0.0698971\tvalid_1's binary_logloss: 0.0472305\n",
      "[40]\ttraining's binary_logloss: 0.0682062\tvalid_1's binary_logloss: 0.0461661\n",
      "[50]\ttraining's binary_logloss: 0.0672992\tvalid_1's binary_logloss: 0.0455991\n",
      "[60]\ttraining's binary_logloss: 0.0667889\tvalid_1's binary_logloss: 0.0452832\n",
      "[70]\ttraining's binary_logloss: 0.0664899\tvalid_1's binary_logloss: 0.0451008\n",
      "[80]\ttraining's binary_logloss: 0.0663065\tvalid_1's binary_logloss: 0.0449928\n",
      "[90]\ttraining's binary_logloss: 0.0661896\tvalid_1's binary_logloss: 0.0449274\n",
      "[100]\ttraining's binary_logloss: 0.0661076\tvalid_1's binary_logloss: 0.0448837\n",
      "[110]\ttraining's binary_logloss: 0.0660456\tvalid_1's binary_logloss: 0.0448528\n",
      "[120]\ttraining's binary_logloss: 0.0659955\tvalid_1's binary_logloss: 0.0448296\n",
      "[130]\ttraining's binary_logloss: 0.0659519\tvalid_1's binary_logloss: 0.0448121\n",
      "[140]\ttraining's binary_logloss: 0.0659134\tvalid_1's binary_logloss: 0.0447983\n",
      "[150]\ttraining's binary_logloss: 0.0658771\tvalid_1's binary_logloss: 0.0447871\n",
      "[160]\ttraining's binary_logloss: 0.0658454\tvalid_1's binary_logloss: 0.0447785\n",
      "[170]\ttraining's binary_logloss: 0.0658159\tvalid_1's binary_logloss: 0.0447712\n",
      "[180]\ttraining's binary_logloss: 0.0657894\tvalid_1's binary_logloss: 0.0447652\n",
      "[190]\ttraining's binary_logloss: 0.0657637\tvalid_1's binary_logloss: 0.0447597\n",
      "[200]\ttraining's binary_logloss: 0.0657378\tvalid_1's binary_logloss: 0.044754\n",
      "[210]\ttraining's binary_logloss: 0.0657093\tvalid_1's binary_logloss: 0.0447478\n",
      "[220]\ttraining's binary_logloss: 0.0656821\tvalid_1's binary_logloss: 0.0447418\n",
      "[230]\ttraining's binary_logloss: 0.0656544\tvalid_1's binary_logloss: 0.0447351\n",
      "[240]\ttraining's binary_logloss: 0.0656305\tvalid_1's binary_logloss: 0.0447305\n",
      "[250]\ttraining's binary_logloss: 0.0656071\tvalid_1's binary_logloss: 0.0447266\n",
      "[260]\ttraining's binary_logloss: 0.0655849\tvalid_1's binary_logloss: 0.0447232\n",
      "[270]\ttraining's binary_logloss: 0.0655643\tvalid_1's binary_logloss: 0.0447208\n",
      "[280]\ttraining's binary_logloss: 0.0655412\tvalid_1's binary_logloss: 0.0447174\n",
      "[290]\ttraining's binary_logloss: 0.0655175\tvalid_1's binary_logloss: 0.0447124\n",
      "[300]\ttraining's binary_logloss: 0.0654951\tvalid_1's binary_logloss: 0.0447096\n",
      "[310]\ttraining's binary_logloss: 0.0654782\tvalid_1's binary_logloss: 0.0447088\n",
      "[320]\ttraining's binary_logloss: 0.0654589\tvalid_1's binary_logloss: 0.0447074\n",
      "[330]\ttraining's binary_logloss: 0.0654387\tvalid_1's binary_logloss: 0.0447048\n",
      "[340]\ttraining's binary_logloss: 0.0654158\tvalid_1's binary_logloss: 0.0447015\n",
      "[350]\ttraining's binary_logloss: 0.0653952\tvalid_1's binary_logloss: 0.0446982\n",
      "[360]\ttraining's binary_logloss: 0.0653743\tvalid_1's binary_logloss: 0.0446946\n",
      "[370]\ttraining's binary_logloss: 0.0653524\tvalid_1's binary_logloss: 0.0446915\n",
      "[380]\ttraining's binary_logloss: 0.0653305\tvalid_1's binary_logloss: 0.0446876\n",
      "[390]\ttraining's binary_logloss: 0.0653095\tvalid_1's binary_logloss: 0.0446851\n",
      "[400]\ttraining's binary_logloss: 0.0652878\tvalid_1's binary_logloss: 0.0446816\n",
      "[410]\ttraining's binary_logloss: 0.0652656\tvalid_1's binary_logloss: 0.0446791\n",
      "[420]\ttraining's binary_logloss: 0.0652449\tvalid_1's binary_logloss: 0.0446766\n",
      "[430]\ttraining's binary_logloss: 0.0652254\tvalid_1's binary_logloss: 0.0446745\n",
      "[440]\ttraining's binary_logloss: 0.0652049\tvalid_1's binary_logloss: 0.0446715\n",
      "[450]\ttraining's binary_logloss: 0.0651848\tvalid_1's binary_logloss: 0.0446694\n",
      "[460]\ttraining's binary_logloss: 0.065169\tvalid_1's binary_logloss: 0.0446684\n",
      "[470]\ttraining's binary_logloss: 0.0651493\tvalid_1's binary_logloss: 0.0446659\n",
      "[480]\ttraining's binary_logloss: 0.0651276\tvalid_1's binary_logloss: 0.0446625\n",
      "[490]\ttraining's binary_logloss: 0.065108\tvalid_1's binary_logloss: 0.0446602\n",
      "[500]\ttraining's binary_logloss: 0.065088\tvalid_1's binary_logloss: 0.0446593\n",
      "[510]\ttraining's binary_logloss: 0.0650708\tvalid_1's binary_logloss: 0.0446586\n",
      "[520]\ttraining's binary_logloss: 0.0650519\tvalid_1's binary_logloss: 0.0446567\n",
      "[530]\ttraining's binary_logloss: 0.065034\tvalid_1's binary_logloss: 0.0446557\n",
      "[540]\ttraining's binary_logloss: 0.0650153\tvalid_1's binary_logloss: 0.044654\n",
      "[550]\ttraining's binary_logloss: 0.0649986\tvalid_1's binary_logloss: 0.0446531\n",
      "[560]\ttraining's binary_logloss: 0.064982\tvalid_1's binary_logloss: 0.0446523\n",
      "[570]\ttraining's binary_logloss: 0.0649642\tvalid_1's binary_logloss: 0.0446509\n",
      "[580]\ttraining's binary_logloss: 0.0649453\tvalid_1's binary_logloss: 0.0446491\n",
      "[590]\ttraining's binary_logloss: 0.0649298\tvalid_1's binary_logloss: 0.0446488\n",
      "[600]\ttraining's binary_logloss: 0.0649108\tvalid_1's binary_logloss: 0.0446472\n",
      "[610]\ttraining's binary_logloss: 0.0648961\tvalid_1's binary_logloss: 0.0446467\n",
      "[620]\ttraining's binary_logloss: 0.0648775\tvalid_1's binary_logloss: 0.0446449\n",
      "[630]\ttraining's binary_logloss: 0.0648604\tvalid_1's binary_logloss: 0.044643\n",
      "[640]\ttraining's binary_logloss: 0.0648442\tvalid_1's binary_logloss: 0.0446419\n",
      "[650]\ttraining's binary_logloss: 0.0648275\tvalid_1's binary_logloss: 0.0446416\n",
      "[660]\ttraining's binary_logloss: 0.0648116\tvalid_1's binary_logloss: 0.0446413\n",
      "[670]\ttraining's binary_logloss: 0.0647945\tvalid_1's binary_logloss: 0.0446399\n",
      "[680]\ttraining's binary_logloss: 0.0647774\tvalid_1's binary_logloss: 0.0446396\n",
      "[690]\ttraining's binary_logloss: 0.0647595\tvalid_1's binary_logloss: 0.0446383\n",
      "[700]\ttraining's binary_logloss: 0.0647438\tvalid_1's binary_logloss: 0.0446376\n",
      "[710]\ttraining's binary_logloss: 0.0647286\tvalid_1's binary_logloss: 0.0446366\n",
      "[720]\ttraining's binary_logloss: 0.0647128\tvalid_1's binary_logloss: 0.0446354\n",
      "[730]\ttraining's binary_logloss: 0.0646968\tvalid_1's binary_logloss: 0.0446343\n",
      "[740]\ttraining's binary_logloss: 0.0646806\tvalid_1's binary_logloss: 0.0446335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[750]\ttraining's binary_logloss: 0.0646638\tvalid_1's binary_logloss: 0.044632\n",
      "[760]\ttraining's binary_logloss: 0.064647\tvalid_1's binary_logloss: 0.0446306\n",
      "[770]\ttraining's binary_logloss: 0.0646307\tvalid_1's binary_logloss: 0.0446293\n",
      "[780]\ttraining's binary_logloss: 0.0646175\tvalid_1's binary_logloss: 0.044629\n",
      "[790]\ttraining's binary_logloss: 0.0646033\tvalid_1's binary_logloss: 0.0446284\n",
      "[800]\ttraining's binary_logloss: 0.0645885\tvalid_1's binary_logloss: 0.0446271\n",
      "[810]\ttraining's binary_logloss: 0.0645733\tvalid_1's binary_logloss: 0.0446265\n",
      "[820]\ttraining's binary_logloss: 0.0645574\tvalid_1's binary_logloss: 0.0446255\n",
      "[830]\ttraining's binary_logloss: 0.0645421\tvalid_1's binary_logloss: 0.0446253\n",
      "[840]\ttraining's binary_logloss: 0.0645284\tvalid_1's binary_logloss: 0.044625\n",
      "[850]\ttraining's binary_logloss: 0.0645141\tvalid_1's binary_logloss: 0.0446244\n",
      "[860]\ttraining's binary_logloss: 0.064498\tvalid_1's binary_logloss: 0.0446239\n",
      "[870]\ttraining's binary_logloss: 0.0644843\tvalid_1's binary_logloss: 0.0446234\n",
      "[880]\ttraining's binary_logloss: 0.0644686\tvalid_1's binary_logloss: 0.0446224\n",
      "[890]\ttraining's binary_logloss: 0.0644529\tvalid_1's binary_logloss: 0.0446219\n",
      "[900]\ttraining's binary_logloss: 0.0644361\tvalid_1's binary_logloss: 0.0446199\n",
      "[910]\ttraining's binary_logloss: 0.0644199\tvalid_1's binary_logloss: 0.0446183\n",
      "[920]\ttraining's binary_logloss: 0.064404\tvalid_1's binary_logloss: 0.0446171\n",
      "[930]\ttraining's binary_logloss: 0.0643874\tvalid_1's binary_logloss: 0.0446164\n",
      "[940]\ttraining's binary_logloss: 0.0643708\tvalid_1's binary_logloss: 0.0446153\n",
      "[950]\ttraining's binary_logloss: 0.0643543\tvalid_1's binary_logloss: 0.0446144\n",
      "[960]\ttraining's binary_logloss: 0.0643376\tvalid_1's binary_logloss: 0.0446136\n",
      "[970]\ttraining's binary_logloss: 0.0643212\tvalid_1's binary_logloss: 0.0446121\n",
      "[980]\ttraining's binary_logloss: 0.0643041\tvalid_1's binary_logloss: 0.0446104\n",
      "[990]\ttraining's binary_logloss: 0.0642881\tvalid_1's binary_logloss: 0.0446089\n",
      "[1000]\ttraining's binary_logloss: 0.0642716\tvalid_1's binary_logloss: 0.0446085\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.0642716\tvalid_1's binary_logloss: 0.0446085\n",
      "train pred i= 0\n",
      "train pred i= 1\n",
      "train pred i= 2\n",
      "train pred i= 3\n",
      "train pred i= 4\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 3...\n",
      "before mean: 0.013401105136138108\n",
      "under sampling....... 1 / 5\n",
      "under sampling....... 2 / 5\n",
      "under sampling....... 3 / 5\n",
      "under sampling....... 4 / 5\n",
      "under sampling....... 5 / 5\n",
      "under sampling end\n",
      "post proccess1\n",
      "after mean: 0.025\n",
      "[LightGBM] [Info] Number of positive: 810188, number of negative: 31597332\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 3.112279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9818\n",
      "[LightGBM] [Info] Number of data points in the train set: 32407520, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.025000 -> initscore=-3.663562\n",
      "[LightGBM] [Info] Start training from score -3.663562\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.0805938\tvalid_1's binary_logloss: 0.0538851\n",
      "[20]\ttraining's binary_logloss: 0.0732257\tvalid_1's binary_logloss: 0.0493169\n",
      "[30]\ttraining's binary_logloss: 0.0698876\tvalid_1's binary_logloss: 0.0472188\n",
      "[40]\ttraining's binary_logloss: 0.0681946\tvalid_1's binary_logloss: 0.0461576\n",
      "[50]\ttraining's binary_logloss: 0.0672862\tvalid_1's binary_logloss: 0.0455941\n",
      "[60]\ttraining's binary_logloss: 0.0667737\tvalid_1's binary_logloss: 0.0452788\n",
      "[70]\ttraining's binary_logloss: 0.066475\tvalid_1's binary_logloss: 0.0450984\n",
      "[80]\ttraining's binary_logloss: 0.0662909\tvalid_1's binary_logloss: 0.0449911\n",
      "[90]\ttraining's binary_logloss: 0.066172\tvalid_1's binary_logloss: 0.0449247\n",
      "[100]\ttraining's binary_logloss: 0.0660892\tvalid_1's binary_logloss: 0.0448815\n",
      "[110]\ttraining's binary_logloss: 0.0660282\tvalid_1's binary_logloss: 0.0448525\n",
      "[120]\ttraining's binary_logloss: 0.0659768\tvalid_1's binary_logloss: 0.0448295\n",
      "[130]\ttraining's binary_logloss: 0.0659322\tvalid_1's binary_logloss: 0.0448122\n",
      "[140]\ttraining's binary_logloss: 0.065897\tvalid_1's binary_logloss: 0.0448\n",
      "[150]\ttraining's binary_logloss: 0.0658603\tvalid_1's binary_logloss: 0.0447876\n",
      "[160]\ttraining's binary_logloss: 0.0658291\tvalid_1's binary_logloss: 0.0447784\n",
      "[170]\ttraining's binary_logloss: 0.0657961\tvalid_1's binary_logloss: 0.0447698\n",
      "[180]\ttraining's binary_logloss: 0.0657704\tvalid_1's binary_logloss: 0.0447651\n",
      "[190]\ttraining's binary_logloss: 0.0657453\tvalid_1's binary_logloss: 0.04476\n",
      "[200]\ttraining's binary_logloss: 0.0657174\tvalid_1's binary_logloss: 0.0447541\n",
      "[210]\ttraining's binary_logloss: 0.0656901\tvalid_1's binary_logloss: 0.0447476\n",
      "[220]\ttraining's binary_logloss: 0.0656645\tvalid_1's binary_logloss: 0.0447425\n",
      "[230]\ttraining's binary_logloss: 0.0656403\tvalid_1's binary_logloss: 0.044739\n",
      "[240]\ttraining's binary_logloss: 0.0656164\tvalid_1's binary_logloss: 0.0447353\n",
      "[250]\ttraining's binary_logloss: 0.0655917\tvalid_1's binary_logloss: 0.0447317\n",
      "[260]\ttraining's binary_logloss: 0.065567\tvalid_1's binary_logloss: 0.0447268\n",
      "[270]\ttraining's binary_logloss: 0.0655407\tvalid_1's binary_logloss: 0.044722\n",
      "[280]\ttraining's binary_logloss: 0.0655198\tvalid_1's binary_logloss: 0.0447194\n",
      "[290]\ttraining's binary_logloss: 0.0654967\tvalid_1's binary_logloss: 0.0447162\n",
      "[300]\ttraining's binary_logloss: 0.0654746\tvalid_1's binary_logloss: 0.0447131\n",
      "[310]\ttraining's binary_logloss: 0.0654519\tvalid_1's binary_logloss: 0.0447098\n",
      "[320]\ttraining's binary_logloss: 0.0654299\tvalid_1's binary_logloss: 0.0447065\n",
      "[330]\ttraining's binary_logloss: 0.0654078\tvalid_1's binary_logloss: 0.0447031\n",
      "[340]\ttraining's binary_logloss: 0.065384\tvalid_1's binary_logloss: 0.0446993\n",
      "[350]\ttraining's binary_logloss: 0.0653614\tvalid_1's binary_logloss: 0.044696\n",
      "[360]\ttraining's binary_logloss: 0.0653404\tvalid_1's binary_logloss: 0.044693\n",
      "[370]\ttraining's binary_logloss: 0.0653187\tvalid_1's binary_logloss: 0.0446904\n",
      "[380]\ttraining's binary_logloss: 0.0652974\tvalid_1's binary_logloss: 0.0446882\n",
      "[390]\ttraining's binary_logloss: 0.0652779\tvalid_1's binary_logloss: 0.0446863\n",
      "[400]\ttraining's binary_logloss: 0.0652589\tvalid_1's binary_logloss: 0.0446851\n",
      "[410]\ttraining's binary_logloss: 0.0652392\tvalid_1's binary_logloss: 0.0446828\n",
      "[420]\ttraining's binary_logloss: 0.0652223\tvalid_1's binary_logloss: 0.0446807\n",
      "[430]\ttraining's binary_logloss: 0.0652029\tvalid_1's binary_logloss: 0.0446785\n",
      "[440]\ttraining's binary_logloss: 0.0651865\tvalid_1's binary_logloss: 0.044677\n",
      "[450]\ttraining's binary_logloss: 0.0651648\tvalid_1's binary_logloss: 0.0446748\n",
      "[460]\ttraining's binary_logloss: 0.0651445\tvalid_1's binary_logloss: 0.0446721\n",
      "[470]\ttraining's binary_logloss: 0.0651239\tvalid_1's binary_logloss: 0.0446701\n",
      "[480]\ttraining's binary_logloss: 0.0651035\tvalid_1's binary_logloss: 0.0446678\n",
      "[490]\ttraining's binary_logloss: 0.0650832\tvalid_1's binary_logloss: 0.0446662\n",
      "[500]\ttraining's binary_logloss: 0.0650643\tvalid_1's binary_logloss: 0.0446638\n",
      "[510]\ttraining's binary_logloss: 0.0650468\tvalid_1's binary_logloss: 0.0446622\n",
      "[520]\ttraining's binary_logloss: 0.0650288\tvalid_1's binary_logloss: 0.044661\n",
      "[530]\ttraining's binary_logloss: 0.0650117\tvalid_1's binary_logloss: 0.0446602\n",
      "[540]\ttraining's binary_logloss: 0.0649943\tvalid_1's binary_logloss: 0.0446586\n",
      "[550]\ttraining's binary_logloss: 0.064975\tvalid_1's binary_logloss: 0.0446572\n",
      "[560]\ttraining's binary_logloss: 0.0649568\tvalid_1's binary_logloss: 0.0446557\n",
      "[570]\ttraining's binary_logloss: 0.0649395\tvalid_1's binary_logloss: 0.0446549\n",
      "[580]\ttraining's binary_logloss: 0.0649241\tvalid_1's binary_logloss: 0.0446547\n",
      "[590]\ttraining's binary_logloss: 0.0649067\tvalid_1's binary_logloss: 0.0446528\n",
      "[600]\ttraining's binary_logloss: 0.064891\tvalid_1's binary_logloss: 0.0446521\n",
      "[610]\ttraining's binary_logloss: 0.0648732\tvalid_1's binary_logloss: 0.0446503\n",
      "[620]\ttraining's binary_logloss: 0.0648534\tvalid_1's binary_logloss: 0.0446485\n",
      "[630]\ttraining's binary_logloss: 0.0648362\tvalid_1's binary_logloss: 0.0446473\n",
      "[640]\ttraining's binary_logloss: 0.0648189\tvalid_1's binary_logloss: 0.0446465\n",
      "[650]\ttraining's binary_logloss: 0.0648014\tvalid_1's binary_logloss: 0.0446456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[660]\ttraining's binary_logloss: 0.0647836\tvalid_1's binary_logloss: 0.044644\n",
      "[670]\ttraining's binary_logloss: 0.064768\tvalid_1's binary_logloss: 0.0446436\n",
      "[680]\ttraining's binary_logloss: 0.0647526\tvalid_1's binary_logloss: 0.0446419\n",
      "[690]\ttraining's binary_logloss: 0.0647345\tvalid_1's binary_logloss: 0.0446414\n",
      "[700]\ttraining's binary_logloss: 0.0647172\tvalid_1's binary_logloss: 0.0446405\n",
      "[710]\ttraining's binary_logloss: 0.0647006\tvalid_1's binary_logloss: 0.0446397\n",
      "[720]\ttraining's binary_logloss: 0.0646843\tvalid_1's binary_logloss: 0.0446384\n",
      "[730]\ttraining's binary_logloss: 0.0646686\tvalid_1's binary_logloss: 0.044638\n",
      "[740]\ttraining's binary_logloss: 0.064655\tvalid_1's binary_logloss: 0.0446378\n",
      "[750]\ttraining's binary_logloss: 0.0646397\tvalid_1's binary_logloss: 0.0446371\n",
      "[760]\ttraining's binary_logloss: 0.0646227\tvalid_1's binary_logloss: 0.0446367\n",
      "[770]\ttraining's binary_logloss: 0.064606\tvalid_1's binary_logloss: 0.0446355\n",
      "[780]\ttraining's binary_logloss: 0.0645889\tvalid_1's binary_logloss: 0.0446344\n",
      "[790]\ttraining's binary_logloss: 0.0645729\tvalid_1's binary_logloss: 0.0446335\n",
      "[800]\ttraining's binary_logloss: 0.0645539\tvalid_1's binary_logloss: 0.0446325\n",
      "[810]\ttraining's binary_logloss: 0.064538\tvalid_1's binary_logloss: 0.044631\n",
      "[820]\ttraining's binary_logloss: 0.0645212\tvalid_1's binary_logloss: 0.0446299\n",
      "[830]\ttraining's binary_logloss: 0.0645044\tvalid_1's binary_logloss: 0.0446286\n",
      "[840]\ttraining's binary_logloss: 0.0644901\tvalid_1's binary_logloss: 0.0446277\n",
      "[850]\ttraining's binary_logloss: 0.0644747\tvalid_1's binary_logloss: 0.0446273\n",
      "[860]\ttraining's binary_logloss: 0.0644586\tvalid_1's binary_logloss: 0.044627\n",
      "[870]\ttraining's binary_logloss: 0.0644429\tvalid_1's binary_logloss: 0.0446256\n",
      "[880]\ttraining's binary_logloss: 0.0644289\tvalid_1's binary_logloss: 0.0446253\n",
      "[890]\ttraining's binary_logloss: 0.0644138\tvalid_1's binary_logloss: 0.0446245\n",
      "[900]\ttraining's binary_logloss: 0.0643975\tvalid_1's binary_logloss: 0.0446239\n",
      "[910]\ttraining's binary_logloss: 0.0643812\tvalid_1's binary_logloss: 0.0446225\n",
      "[920]\ttraining's binary_logloss: 0.0643669\tvalid_1's binary_logloss: 0.0446218\n",
      "[930]\ttraining's binary_logloss: 0.064354\tvalid_1's binary_logloss: 0.0446215\n",
      "[940]\ttraining's binary_logloss: 0.0643381\tvalid_1's binary_logloss: 0.0446206\n",
      "[950]\ttraining's binary_logloss: 0.0643231\tvalid_1's binary_logloss: 0.0446202\n",
      "[960]\ttraining's binary_logloss: 0.0643073\tvalid_1's binary_logloss: 0.0446193\n",
      "[970]\ttraining's binary_logloss: 0.0642931\tvalid_1's binary_logloss: 0.0446185\n",
      "[980]\ttraining's binary_logloss: 0.0642762\tvalid_1's binary_logloss: 0.044618\n",
      "[990]\ttraining's binary_logloss: 0.0642595\tvalid_1's binary_logloss: 0.044617\n",
      "[1000]\ttraining's binary_logloss: 0.064244\tvalid_1's binary_logloss: 0.0446158\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.064244\tvalid_1's binary_logloss: 0.0446158\n",
      "train pred i= 0\n",
      "train pred i= 1\n",
      "train pred i= 2\n",
      "train pred i= 3\n",
      "train pred i= 4\n",
      " \n",
      "--------------------------------------------------\n",
      "Training fold 4...\n",
      "before mean: 0.013401824918228965\n",
      "under sampling....... 1 / 5\n",
      "under sampling....... 2 / 5\n",
      "under sampling....... 3 / 5\n",
      "under sampling....... 4 / 5\n",
      "under sampling....... 5 / 5\n",
      "under sampling end\n",
      "post proccess1\n",
      "after mean: 0.025\n",
      "[LightGBM] [Info] Number of positive: 810188, number of negative: 31597332\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.781856 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9793\n",
      "[LightGBM] [Info] Number of data points in the train set: 32407520, number of used features: 48\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.025000 -> initscore=-3.663562\n",
      "[LightGBM] [Info] Start training from score -3.663562\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[10]\ttraining's binary_logloss: 0.0805835\tvalid_1's binary_logloss: 0.0538851\n",
      "[20]\ttraining's binary_logloss: 0.0732108\tvalid_1's binary_logloss: 0.0493214\n",
      "[30]\ttraining's binary_logloss: 0.0698717\tvalid_1's binary_logloss: 0.0472262\n",
      "[40]\ttraining's binary_logloss: 0.0681802\tvalid_1's binary_logloss: 0.0461681\n",
      "[50]\ttraining's binary_logloss: 0.0672697\tvalid_1's binary_logloss: 0.0456043\n",
      "[60]\ttraining's binary_logloss: 0.0667544\tvalid_1's binary_logloss: 0.0452898\n",
      "[70]\ttraining's binary_logloss: 0.0664526\tvalid_1's binary_logloss: 0.0451093\n",
      "[80]\ttraining's binary_logloss: 0.0662695\tvalid_1's binary_logloss: 0.0450032\n",
      "[90]\ttraining's binary_logloss: 0.066152\tvalid_1's binary_logloss: 0.044939\n",
      "[100]\ttraining's binary_logloss: 0.0660695\tvalid_1's binary_logloss: 0.0448966\n",
      "[110]\ttraining's binary_logloss: 0.0660078\tvalid_1's binary_logloss: 0.0448679\n",
      "[120]\ttraining's binary_logloss: 0.0659562\tvalid_1's binary_logloss: 0.0448445\n",
      "[130]\ttraining's binary_logloss: 0.0659146\tvalid_1's binary_logloss: 0.0448276\n",
      "[140]\ttraining's binary_logloss: 0.0658751\tvalid_1's binary_logloss: 0.0448145\n",
      "[150]\ttraining's binary_logloss: 0.0658375\tvalid_1's binary_logloss: 0.0448017\n",
      "[160]\ttraining's binary_logloss: 0.0658039\tvalid_1's binary_logloss: 0.0447917\n",
      "[170]\ttraining's binary_logloss: 0.0657719\tvalid_1's binary_logloss: 0.0447828\n",
      "[180]\ttraining's binary_logloss: 0.0657438\tvalid_1's binary_logloss: 0.0447765\n",
      "[190]\ttraining's binary_logloss: 0.0657146\tvalid_1's binary_logloss: 0.0447707\n",
      "[200]\ttraining's binary_logloss: 0.0656875\tvalid_1's binary_logloss: 0.044765\n",
      "[210]\ttraining's binary_logloss: 0.065663\tvalid_1's binary_logloss: 0.0447607\n",
      "[220]\ttraining's binary_logloss: 0.0656367\tvalid_1's binary_logloss: 0.0447561\n",
      "[230]\ttraining's binary_logloss: 0.0656148\tvalid_1's binary_logloss: 0.0447534\n",
      "[240]\ttraining's binary_logloss: 0.0655904\tvalid_1's binary_logloss: 0.0447499\n",
      "[250]\ttraining's binary_logloss: 0.0655677\tvalid_1's binary_logloss: 0.0447466\n",
      "[260]\ttraining's binary_logloss: 0.0655445\tvalid_1's binary_logloss: 0.044743\n",
      "[270]\ttraining's binary_logloss: 0.0655211\tvalid_1's binary_logloss: 0.0447395\n",
      "[280]\ttraining's binary_logloss: 0.0654975\tvalid_1's binary_logloss: 0.0447352\n",
      "[290]\ttraining's binary_logloss: 0.0654768\tvalid_1's binary_logloss: 0.0447326\n",
      "[300]\ttraining's binary_logloss: 0.0654523\tvalid_1's binary_logloss: 0.0447286\n",
      "[310]\ttraining's binary_logloss: 0.0654311\tvalid_1's binary_logloss: 0.044726\n",
      "[320]\ttraining's binary_logloss: 0.0654119\tvalid_1's binary_logloss: 0.0447236\n",
      "[330]\ttraining's binary_logloss: 0.0653925\tvalid_1's binary_logloss: 0.0447218\n",
      "[340]\ttraining's binary_logloss: 0.0653721\tvalid_1's binary_logloss: 0.0447186\n",
      "[350]\ttraining's binary_logloss: 0.06535\tvalid_1's binary_logloss: 0.0447157\n",
      "[360]\ttraining's binary_logloss: 0.0653302\tvalid_1's binary_logloss: 0.0447134\n",
      "[370]\ttraining's binary_logloss: 0.0653098\tvalid_1's binary_logloss: 0.044712\n",
      "[380]\ttraining's binary_logloss: 0.0652891\tvalid_1's binary_logloss: 0.0447097\n",
      "[390]\ttraining's binary_logloss: 0.0652682\tvalid_1's binary_logloss: 0.0447069\n",
      "[400]\ttraining's binary_logloss: 0.0652491\tvalid_1's binary_logloss: 0.0447047\n",
      "[410]\ttraining's binary_logloss: 0.0652308\tvalid_1's binary_logloss: 0.0447033\n",
      "[420]\ttraining's binary_logloss: 0.0652119\tvalid_1's binary_logloss: 0.0447005\n",
      "[430]\ttraining's binary_logloss: 0.0651924\tvalid_1's binary_logloss: 0.0446981\n",
      "[440]\ttraining's binary_logloss: 0.0651705\tvalid_1's binary_logloss: 0.0446952\n",
      "[450]\ttraining's binary_logloss: 0.0651513\tvalid_1's binary_logloss: 0.0446928\n",
      "[460]\ttraining's binary_logloss: 0.0651335\tvalid_1's binary_logloss: 0.0446915\n",
      "[470]\ttraining's binary_logloss: 0.0651142\tvalid_1's binary_logloss: 0.0446898\n",
      "[480]\ttraining's binary_logloss: 0.0650953\tvalid_1's binary_logloss: 0.0446885\n",
      "[490]\ttraining's binary_logloss: 0.0650757\tvalid_1's binary_logloss: 0.0446874\n",
      "[500]\ttraining's binary_logloss: 0.0650556\tvalid_1's binary_logloss: 0.0446855\n",
      "[510]\ttraining's binary_logloss: 0.065036\tvalid_1's binary_logloss: 0.044684\n",
      "[520]\ttraining's binary_logloss: 0.0650169\tvalid_1's binary_logloss: 0.044682\n",
      "[530]\ttraining's binary_logloss: 0.0650003\tvalid_1's binary_logloss: 0.0446809\n",
      "[540]\ttraining's binary_logloss: 0.0649805\tvalid_1's binary_logloss: 0.0446788\n",
      "[550]\ttraining's binary_logloss: 0.0649632\tvalid_1's binary_logloss: 0.0446779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[560]\ttraining's binary_logloss: 0.0649455\tvalid_1's binary_logloss: 0.0446769\n",
      "[570]\ttraining's binary_logloss: 0.0649287\tvalid_1's binary_logloss: 0.0446758\n",
      "[580]\ttraining's binary_logloss: 0.06491\tvalid_1's binary_logloss: 0.0446741\n",
      "[590]\ttraining's binary_logloss: 0.0648924\tvalid_1's binary_logloss: 0.044673\n",
      "[600]\ttraining's binary_logloss: 0.064875\tvalid_1's binary_logloss: 0.0446718\n",
      "[610]\ttraining's binary_logloss: 0.0648565\tvalid_1's binary_logloss: 0.0446702\n",
      "[620]\ttraining's binary_logloss: 0.0648384\tvalid_1's binary_logloss: 0.0446685\n",
      "[630]\ttraining's binary_logloss: 0.0648212\tvalid_1's binary_logloss: 0.0446671\n",
      "[640]\ttraining's binary_logloss: 0.0648043\tvalid_1's binary_logloss: 0.0446655\n",
      "[650]\ttraining's binary_logloss: 0.0647886\tvalid_1's binary_logloss: 0.0446637\n",
      "[660]\ttraining's binary_logloss: 0.0647726\tvalid_1's binary_logloss: 0.0446632\n",
      "[670]\ttraining's binary_logloss: 0.0647573\tvalid_1's binary_logloss: 0.044663\n",
      "[680]\ttraining's binary_logloss: 0.0647429\tvalid_1's binary_logloss: 0.0446627\n",
      "[690]\ttraining's binary_logloss: 0.0647246\tvalid_1's binary_logloss: 0.0446616\n",
      "[700]\ttraining's binary_logloss: 0.0647088\tvalid_1's binary_logloss: 0.0446611\n",
      "[710]\ttraining's binary_logloss: 0.0646951\tvalid_1's binary_logloss: 0.044661\n",
      "[720]\ttraining's binary_logloss: 0.0646786\tvalid_1's binary_logloss: 0.0446604\n",
      "[730]\ttraining's binary_logloss: 0.0646633\tvalid_1's binary_logloss: 0.0446591\n",
      "[740]\ttraining's binary_logloss: 0.0646497\tvalid_1's binary_logloss: 0.0446584\n",
      "[750]\ttraining's binary_logloss: 0.0646319\tvalid_1's binary_logloss: 0.0446572\n",
      "[760]\ttraining's binary_logloss: 0.064616\tvalid_1's binary_logloss: 0.0446571\n",
      "[770]\ttraining's binary_logloss: 0.0645989\tvalid_1's binary_logloss: 0.0446559\n",
      "[780]\ttraining's binary_logloss: 0.0645841\tvalid_1's binary_logloss: 0.0446548\n",
      "[790]\ttraining's binary_logloss: 0.0645675\tvalid_1's binary_logloss: 0.044654\n",
      "[800]\ttraining's binary_logloss: 0.0645488\tvalid_1's binary_logloss: 0.044653\n",
      "[810]\ttraining's binary_logloss: 0.0645339\tvalid_1's binary_logloss: 0.0446522\n",
      "[820]\ttraining's binary_logloss: 0.06452\tvalid_1's binary_logloss: 0.0446518\n",
      "[830]\ttraining's binary_logloss: 0.0645046\tvalid_1's binary_logloss: 0.0446516\n",
      "[840]\ttraining's binary_logloss: 0.0644897\tvalid_1's binary_logloss: 0.0446507\n",
      "[850]\ttraining's binary_logloss: 0.0644743\tvalid_1's binary_logloss: 0.0446498\n",
      "[860]\ttraining's binary_logloss: 0.0644575\tvalid_1's binary_logloss: 0.0446489\n",
      "[870]\ttraining's binary_logloss: 0.0644418\tvalid_1's binary_logloss: 0.0446481\n",
      "[880]\ttraining's binary_logloss: 0.0644253\tvalid_1's binary_logloss: 0.0446477\n",
      "[890]\ttraining's binary_logloss: 0.0644091\tvalid_1's binary_logloss: 0.0446465\n",
      "[900]\ttraining's binary_logloss: 0.0643933\tvalid_1's binary_logloss: 0.0446455\n",
      "[910]\ttraining's binary_logloss: 0.0643795\tvalid_1's binary_logloss: 0.0446449\n",
      "[920]\ttraining's binary_logloss: 0.0643633\tvalid_1's binary_logloss: 0.0446444\n",
      "[930]\ttraining's binary_logloss: 0.0643478\tvalid_1's binary_logloss: 0.0446437\n",
      "[940]\ttraining's binary_logloss: 0.064333\tvalid_1's binary_logloss: 0.0446429\n",
      "[950]\ttraining's binary_logloss: 0.0643162\tvalid_1's binary_logloss: 0.0446418\n",
      "[960]\ttraining's binary_logloss: 0.064302\tvalid_1's binary_logloss: 0.0446411\n",
      "[970]\ttraining's binary_logloss: 0.0642886\tvalid_1's binary_logloss: 0.0446399\n",
      "[980]\ttraining's binary_logloss: 0.064272\tvalid_1's binary_logloss: 0.0446383\n",
      "[990]\ttraining's binary_logloss: 0.0642576\tvalid_1's binary_logloss: 0.0446376\n",
      "[1000]\ttraining's binary_logloss: 0.0642425\tvalid_1's binary_logloss: 0.0446357\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\ttraining's binary_logloss: 0.0642425\tvalid_1's binary_logloss: 0.0446357\n",
      "train pred i= 0\n",
      "train pred i= 1\n",
      "train pred i= 2\n",
      "train pred i= 3\n",
      "train pred i= 4\n"
     ]
    }
   ],
   "source": [
    "# Create a numpy array to store out of folds predictions\n",
    "oof_predictions = np.zeros(len(train))\n",
    "session = train['session']\n",
    "unique_session = session.unique()\n",
    "\n",
    "kfold = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "for fold, (trn_group_ind, val_group_ind) in enumerate(kfold.split(unique_session)):\n",
    "    print(' ')\n",
    "    print('-'*50)\n",
    "    print(f'Training fold {fold}...')\n",
    "    # session単位で分割してKFoldする\n",
    "    tr_groups, va_groups = unique_session[trn_group_ind], unique_session[val_group_ind]\n",
    "    is_tr, is_va = session.isin(tr_groups), session.isin(va_groups)\n",
    "    del tr_groups, va_groups\n",
    "    gc.collect()\n",
    "    # is_ir, is_va=Trueのindexを取得\n",
    "    trn_ind, val_ind = is_tr[is_tr].index, is_va[is_va].index\n",
    "    del is_tr, is_va\n",
    "    gc.collect()\n",
    "\n",
    "    y_train, y_val = train[target].iloc[trn_ind], train[target].iloc[val_ind]\n",
    "    train_tmp = train.drop(IGNORE_COL , axis=1)\n",
    "    x_train, x_val = train_tmp.iloc[trn_ind], train_tmp.iloc[val_ind]\n",
    "    \n",
    "    del train_tmp\n",
    "    gc.collect()\n",
    "\n",
    "    # under sampling\n",
    "    x_train, y_train = negative_sampling(x_train, y_train, pos_neg_ratio)\n",
    "\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(x_val, y_val)\n",
    "    del x_train, y_train\n",
    "    gc.collect()\n",
    "\n",
    "    #lgb_valid = lgb.Dataset(x_val, y_val)\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set = lgb_train,\n",
    "        #num_boost_round = 10500,\n",
    "        num_boost_round = 2000,\n",
    "        valid_sets = [lgb_train, lgb_valid],\n",
    "        early_stopping_rounds = 20,\n",
    "        verbose_eval = 10\n",
    "        )\n",
    "    del lgb_train, lgb_valid\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    # Save best model\n",
    "    if TRAIN_SECOND:\n",
    "        joblib.dump(model, f'{base_path}/otto/otto_lgbm_fold{fold}_{TYPE_MODE}_second.pkl')\n",
    "    else:\n",
    "        joblib.dump(model, f'{base_path}/otto/otto_lgbm_fold{fold}_{TYPE_MODE}.pkl')\n",
    "    # Predict validation\n",
    "    # でかいので分割してpredict\n",
    "    Nrow = x_val.shape[0]\n",
    "    Ndiv = 5\n",
    "    n = int(Nrow // Ndiv) + 1\n",
    "    x_val_list = []\n",
    "    for i in range(Ndiv):\n",
    "        tmp = x_val.iloc[i*n : (i+1)*n, :]\n",
    "        x_val_list.append(tmp)\n",
    "    del x_val\n",
    "    gc.collect()\n",
    "\n",
    "    val_pred_list = []\n",
    "    for i, v in enumerate(x_val_list):\n",
    "        print('train pred i=', i)\n",
    "        tmp = model.predict(v)\n",
    "        val_pred_list.append(tmp)\n",
    "    del x_val_list\n",
    "    gc.collect()\n",
    "    val_pred = np.concatenate(val_pred_list)\n",
    "    del val_pred_list\n",
    "    gc.collect()\n",
    "\n",
    "    # Add to out of folds array\n",
    "    # CVを終えれば全部のindexが1回ずつ計算されることになる\n",
    "    oof_predictions[val_ind] = val_pred\n",
    "\n",
    "    # 不要になった時点でモデル削除\n",
    "    del model, y_val\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 51120,
     "status": "ok",
     "timestamp": 1673497831521,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "x0DTGgkdT2si",
    "outputId": "fb7d0068-8c34-4604-c5b0-f608653e5afe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_type</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098529_clicks</td>\n",
       "      <td>1105029 459126 217742 295362 1544564 1694360 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11098534_clicks</td>\n",
       "      <td>223062 908024 1342293 1607945 530377 1300062 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11098535_clicks</td>\n",
       "      <td>745365 1750442 803918 767201 236461 896972 132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11098538_clicks</td>\n",
       "      <td>1263747 1550143 1711586 703265 1172033 717871 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11098539_clicks</td>\n",
       "      <td>631008 1408458 1658802 1057728 1251433 617897 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012730</th>\n",
       "      <td>12899773_clicks</td>\n",
       "      <td>1311526 1484665 1578804 337571 184006 104552 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012731</th>\n",
       "      <td>12899774_clicks</td>\n",
       "      <td>33035 1539309 819288 771913 270852 218795 9548...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012732</th>\n",
       "      <td>12899775_clicks</td>\n",
       "      <td>1743151 1760714 1163166 1255910 1022572 832192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012733</th>\n",
       "      <td>12899777_clicks</td>\n",
       "      <td>384045 1308634 1688215 703474 395762 364190 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012734</th>\n",
       "      <td>12899778_clicks</td>\n",
       "      <td>561560 1167224 13942 566042 32070 1320960 1175...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1012735 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            session_type                                             labels\n",
       "0        11098529_clicks  1105029 459126 217742 295362 1544564 1694360 6...\n",
       "1        11098534_clicks  223062 908024 1342293 1607945 530377 1300062 1...\n",
       "2        11098535_clicks  745365 1750442 803918 767201 236461 896972 132...\n",
       "3        11098538_clicks  1263747 1550143 1711586 703265 1172033 717871 ...\n",
       "4        11098539_clicks  631008 1408458 1658802 1057728 1251433 617897 ...\n",
       "...                  ...                                                ...\n",
       "1012730  12899773_clicks  1311526 1484665 1578804 337571 184006 104552 1...\n",
       "1012731  12899774_clicks  33035 1539309 819288 771913 270852 218795 9548...\n",
       "1012732  12899775_clicks  1743151 1760714 1163166 1255910 1022572 832192...\n",
       "1012733  12899777_clicks  384045 1308634 1688215 703474 395762 364190 14...\n",
       "1012734  12899778_clicks  561560 1167224 13942 566042 32070 1320960 1175...\n",
       "\n",
       "[1012735 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(oof_predictions, columns=[\"score\"])\n",
    "if not TRAIN_SECOND:\n",
    "    df.to_csv(f'{base_path}/otto/train_oof_lgbm_{TYPE_MODE}.csv', index = False)\n",
    "\n",
    "pred_df = pd.concat([train[['session', 'aid']], df], axis=1)\n",
    "pred_df['session_type'] = pred_df['session'].apply(lambda x: str(x) + f'_{TYPE_MODE}')\n",
    "pred_df = pred_df.sort_values(['session_type','score'],ascending=[True, False]).reset_index(drop=True)\n",
    "\n",
    "pred_df['n'] = pred_df.groupby('session_type').cumcount()\n",
    "pred_df = pred_df.loc[pred_df.n<20].drop(['n','score','session'],axis=1)\n",
    "pred_df['aid'] = pred_df['aid'].astype('int32')\n",
    "pred_df = pred_df.groupby('session_type')['aid'].apply(list).reset_index()\n",
    "pred_df['labels'] = pred_df['aid'].map(lambda x: ''.join(str(x)[1:-1].split(',')))\n",
    "pred_df = pred_df.drop(['aid'],axis=1)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14063,
     "status": "ok",
     "timestamp": 1673497845580,
     "user": {
      "displayName": "テッツォ",
      "userId": "07789339878611604425"
     },
     "user_tz": -540
    },
    "id": "6Jd5N7_5V44c",
    "outputId": "bc567a74-76bd-44c1-d629-9f3532d42809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clicks recall = 0.5350195439108556\n"
     ]
    }
   ],
   "source": [
    "sub = pred_df.loc[pred_df.session_type.str.contains(TYPE_MODE)].copy()\n",
    "sub['session'] = sub.session_type.apply(lambda x: int(x.split('_')[0]))\n",
    "sub.labels = sub.labels.apply(lambda x: [int(i) for i in x.split(' ')[:20]])\n",
    "\n",
    "test_labels = pd.read_parquet(f'{base_path}/input/otto/otto-validation/test_labels.parquet')\n",
    "test_labels = test_labels.loc[test_labels['type']==TYPE_MODE]\n",
    "test_labels = test_labels.merge(sub, how='left', on=['session'])\n",
    "test_labels['labels'] = test_labels['labels'].fillna('[]')\n",
    "test_labels['hits'] = test_labels.apply(lambda df: len(set(df.ground_truth).intersection(set(df.labels))), axis=1)\n",
    "test_labels['gt_count'] = test_labels.ground_truth.str.len().clip(0,20)\n",
    "recall = test_labels['hits'].sum() / test_labels['gt_count'].sum()\n",
    "print(f'{TYPE_MODE} recall =',recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiU5CW6NeKKS"
   },
   "outputs": [],
   "source": [
    "# click total: 1,755,534\n",
    "# 0.52なら912,877の正解が必要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LskmzPtiPuzJ"
   },
   "outputs": [],
   "source": [
    "# clicks recall = 0.5271239406357268 おためしtop20, , PB = 0.579\n",
    "\n",
    "# baseline top20のitem2itemを使ってgenerateしたもの, trainsform, duplicate削減、negativeのみremove\n",
    "# clicks recall = 0.5279590141803007 num=100 きた！\n",
    "# 既存データ + 50までbackfill, 20位まで num=100 clicks recall = 0.5289963053976738 きた！\n",
    "#                                               orders recall = 0.6531281219777659\n",
    "# 既存データ + 50までbackfill, 30位まで num=100 orders recall = 0.6533100544839979\n",
    "# 既存データ + 50までbackfill, 50位まで num=100 orders recall = 0.6536483851096223\n",
    "# 既存データ + 50までbackfill, 50位まで num=1000(137) orders recall = 0.6536451933112674\n",
    "\n",
    "# under samplingなしだと上位50で2.1%がpositive\n",
    "# 既存データ + 50までbackfill under sampling pos:neg = 1:2 33% pos, orders recall = 0.6190460991436405\n",
    "#                                            pos:neg = 1:9 10% pos, orders recall = 0.6536036999326531\n",
    "#                                            pos:neg = 1:19 5% pos, orders recall = 0.6536388097145575 ちょい下がるけどそんなに問題なさそう\n",
    "#                                            pos:neg = 1:39 2.5% pos,orders recall= 0.6536930702865916 これくらいの比率で固定しよう, PB = 0.580\n",
    "#                                                                    carts recall = 0.41731398378440265\n",
    "#                                                                    clicks recall = 0.5295727681719636\n",
    "# feature増版、click i2i, top10,20 pos:neg = 1:39 2.5%, num=100 orders recall = 0.6538813863895334\n",
    "#                                                      num=1000 orders recall = 0.654031400912216 , PB = 0.581\n",
    "#                                                      num=1000 carts recall = 0.41827325050912256 \n",
    "#                                                      num=1000 clicks recall = 0.5309427217017728\n",
    "# aid feature追加 2weeks, 4weeks                                orders recall = 0.6575391873043028 ほぼ変わらんのでこっち\n",
    "# 2,3,4 weeks                                                   orders recall = 0.6575551462960776\n",
    "# 2,4 under sampling のsplitだけ変えた                          orders recall = 0.6576381330533062, PB = 0.585\n",
    "#                                                               carts recall = 0.4219628713472407\n",
    "#                                                               clicks_recall = 0.5343416874865425\n",
    "# binary_logloss -> auc, orders recall = 0.6573189532178115 -> binary_loglossのままで良さそう\n",
    "# lr 0.1 -> 0.05, orders recall = 0.6577275034072447 ちょびっとだけ上がった\n",
    "# optuna again (lr=0.05, num=200, order) orders recall = 0.6578519835430877 \n",
    "# (other target leak 0.6839768530783299)\n",
    "\n",
    "# kfold古\n",
    "# session feature bug fix orders recall = 0.6576892018269854 logloss下がったのにrecall下がった。。, num=402 valid_1's binary_logloss: 0.0378125\n",
    "# 古いsession素性残し num=335, valid_1's binary_logloss: 0.0378245\n",
    "\n",
    "# kfold sessionごとに変更してsessionのleak修正, 元々のsession素性, orders recall = 0.6577498459957294 [248] valid_1's binary_logloss: 0.0388062\n",
    "# session bug fix orders recall = 0.6579477374937361 [332] valid_1's binary_logloss: 0.0384341 -> binary_loglossがそろそろ信用できない。。\n",
    "#                 carts recall = 0.4225023504636745\n",
    "# session bug fix + 古い素性残 orders recall = 0.6577562295924393 [272] valid_1's binary_logloss: 0.0384143\n",
    "\n",
    "# recallをmetricsに変更 (otto_lgb_train_rank.ipynb)\n",
    "# session bug fix,orders recall = 0.6577945311726986 [283] valid_1's ndcg@20: 0.843099\tvalid_1's ndcg@50: 0.85066, 時間かかるけどそんなに変わらん\n",
    "# session bug fix,orders recall = 0.657772188584214 map [205] valid_1's map@20: 0.790326\tvalid_1's map@50: 0.792477\n",
    "\n",
    "# cart予測値をorderに加えてみたい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NS3YOf-UgmrY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
